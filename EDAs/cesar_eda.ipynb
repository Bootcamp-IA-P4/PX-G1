{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"../data/youtoxic_english_1000.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones del dataset\n",
    "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "\n",
    "df.info()\n",
    "\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n del target IsToxic\n",
    "sns.countplot(x=\"IsToxic\", data=df)\n",
    "plt.title(\"Distribuci√≥n de comentarios t√≥xicos vs no t√≥xicos\")\n",
    "plt.xlabel(\"¬øEs t√≥xico?\")\n",
    "plt.ylabel(\"N√∫mero de comentarios\")\n",
    "plt.show()\n",
    "\n",
    "# Porcentaje de cada clase\n",
    "toxicity_ratio = df[\"IsToxic\"].value_counts(normalize=True) * 100\n",
    "print(\"Distribuci√≥n porcentual:\\n\", toxicity_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columnas nuevas para an√°lisis de texto\n",
    "df[\"text_length_chars\"] = df[\"Text\"].apply(len)\n",
    "df[\"text_length_words\"] = df[\"Text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Mostrar estad√≠sticos por tipo de comentario\n",
    "df.groupby(\"IsToxic\")[[\"text_length_chars\", \"text_length_words\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para comparar longitud de texto por clase\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.boxplot(x=\"IsToxic\", y=\"text_length_chars\", data=df, ax=axes[0])\n",
    "axes[0].set_title(\"Longitud en caracteres por tipo de comentario\")\n",
    "\n",
    "sns.boxplot(x=\"IsToxic\", y=\"text_length_words\", data=df, ax=axes[1])\n",
    "axes[1].set_title(\"Longitud en palabras por tipo de comentario\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Comparativa de longitud de los comentarios (Boxplot)\n",
    "\n",
    "En esta visualizaci√≥n comparamos la **longitud de los comentarios t√≥xicos y no t√≥xicos**, tanto en n√∫mero de caracteres como de palabras.\n",
    "\n",
    "#### ¬øQu√© es un boxplot?\n",
    "Un **boxplot** (o diagrama de caja) es una representaci√≥n visual que nos permite ver:\n",
    "- La **mediana** del conjunto de datos (l√≠nea central de la caja).\n",
    "- El **rango intercuart√≠lico** (donde se concentra el 50% de los valores).\n",
    "- Los **valores extremos o outliers** (representados como puntos).\n",
    "\n",
    "#### ¬øQu√© vemos en estos gr√°ficos?\n",
    "- La longitud de los comentarios **t√≥xicos y no t√≥xicos** es muy similar.\n",
    "- Hay **muchos comentarios cortos** en ambos grupos.\n",
    "- Aparecen **algunos comentarios muy largos** (outliers), especialmente en caracteres.\n",
    "- No se observa una diferencia clara que nos permita decir que un tipo de comentario sea m√°s largo que otro de forma sistem√°tica.\n",
    "\n",
    "#### ¬øQu√© concluimos?\n",
    "Aunque puede haber peque√±as diferencias, **la longitud del comentario no parece ser un buen indicador por s√≠ solo de si un comentario es t√≥xico o no**. Aun as√≠, es √∫til conocer estas caracter√≠sticas para posibles decisiones de preprocesamiento, como filtrar comentarios excesivamente largos o cortos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar comentarios t√≥xicos y no t√≥xicos\n",
    "toxic_comments = df[df[\"IsToxic\"] == True][\"Text\"]\n",
    "nontoxic_comments = df[df[\"IsToxic\"] == False][\"Text\"]\n",
    "\n",
    "# Juntarlos en dos grandes textos para analizarlos\n",
    "toxic_text = \" \".join(toxic_comments).lower()\n",
    "nontoxic_text = \" \".join(nontoxic_comments).lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### An√°lisis del contenido textual\n",
    "\n",
    "Para entender mejor las diferencias entre los comentarios t√≥xicos y no t√≥xicos, hemos separado los textos en dos grupos:\n",
    "\n",
    "- Comentarios etiquetados como **t√≥xicos**.\n",
    "- Comentarios etiquetados como **no t√≥xicos**.\n",
    "\n",
    "Hemos unido los comentarios de cada grupo en un √∫nico texto para poder analizar qu√© palabras aparecen con mayor frecuencia en cada uno. Este enfoque nos permitir√° visualizar patrones de lenguaje caracter√≠sticos, que luego pueden ser clave para entrenar un modelo predictivo.\n",
    "\n",
    "En los pr√≥ximos pasos generaremos:\n",
    "- Listados de palabras m√°s frecuentes.\n",
    "- Nubes de palabras (*wordclouds*).\n",
    "- N-gramas m√°s comunes (combinaciones t√≠picas de 2-3 palabras).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Funci√≥n para limpiar texto b√°sico (sin lematizar a√∫n)\n",
    "def limpiar_texto(texto):\n",
    "    texto = re.sub(r\"[^\\w\\s]\", \"\", texto)  # quitar signos de puntuaci√≥n\n",
    "    texto = texto.lower()  # pasar a min√∫sculas\n",
    "    return texto\n",
    "\n",
    "# Aplicar limpieza y dividir en palabras\n",
    "palabras_toxicas = limpiar_texto(toxic_text).split()\n",
    "palabras_no_toxicas = limpiar_texto(nontoxic_text).split()\n",
    "\n",
    "# Contar palabras m√°s comunes\n",
    "frecuentes_toxicas = Counter(palabras_toxicas).most_common(10)\n",
    "frecuentes_no_toxicas = Counter(palabras_no_toxicas).most_common(10)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"üî¥ Palabras m√°s frecuentes en comentarios t√≥xicos:\")\n",
    "for palabra, freq in frecuentes_toxicas:\n",
    "    print(f\"{palabra}: {freq}\")\n",
    "\n",
    "print(\"\\nüü¢ Palabras m√°s frecuentes en comentarios no t√≥xicos:\")\n",
    "for palabra, freq in frecuentes_no_toxicas:\n",
    "    print(f\"{palabra}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Lista de stopwords en ingl√©s\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Funci√≥n mejorada que filtra stopwords\n",
    "def limpiar_y_filtrar(texto):\n",
    "    texto = re.sub(r\"[^\\w\\s]\", \"\", texto.lower())\n",
    "    palabras = texto.split()\n",
    "    return [p for p in palabras if p not in stop_words]\n",
    "\n",
    "# Aplicar funci√≥n mejorada\n",
    "palabras_toxicas_filtradas = limpiar_y_filtrar(toxic_text)\n",
    "palabras_no_toxicas_filtradas = limpiar_y_filtrar(nontoxic_text)\n",
    "\n",
    "# Contar palabras m√°s frecuentes (filtradas)\n",
    "frecuentes_toxicas_filtradas = Counter(palabras_toxicas_filtradas).most_common(10)\n",
    "frecuentes_no_toxicas_filtradas = Counter(palabras_no_toxicas_filtradas).most_common(10)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"üî¥ Palabras m√°s frecuentes (t√≥xicos, sin stopwords):\")\n",
    "for palabra, freq in frecuentes_toxicas_filtradas:\n",
    "    print(f\"{palabra}: {freq}\")\n",
    "\n",
    "print(\"\\nüü¢ Palabras m√°s frecuentes (no t√≥xicos, sin stopwords):\")\n",
    "for palabra, freq in frecuentes_no_toxicas_filtradas:\n",
    "    print(f\"{palabra}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### An√°lisis con eliminaci√≥n de stopwords\n",
    "\n",
    "Las palabras m√°s frecuentes que observamos inicialmente eran muy comunes y poco informativas. Por ello, hemos repetido el an√°lisis **eliminando las stopwords**, es decir, palabras muy frecuentes en ingl√©s que no aportan significado real (como \"the\", \"and\", \"is\", etc.).\n",
    "\n",
    "Esta limpieza **no forma a√∫n parte del preprocesamiento oficial**, pero se introduce aqu√≠ como una forma de enriquecer el EDA y tomar decisiones m√°s informadas.\n",
    "\n",
    "Ahora los resultados empiezan a revelar **patrones de contenido m√°s relevantes** para entender qu√© vocabulario podr√≠a distinguir los comentarios t√≥xicos de los no t√≥xicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Unir las palabras ya filtradas\n",
    "texto_toxico_filtrado = \" \".join(palabras_toxicas_filtradas)\n",
    "texto_nontoxico_filtrado = \" \".join(palabras_no_toxicas_filtradas)\n",
    "\n",
    "# Crear las nubes\n",
    "wc_toxico = WordCloud(width=800, height=400, background_color=\"white\").generate(texto_toxico_filtrado)\n",
    "wc_nontoxico = WordCloud(width=800, height=400, background_color=\"white\").generate(texto_nontoxico_filtrado)\n",
    "\n",
    "# Mostrar\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "axs[0].imshow(wc_toxico, interpolation=\"bilinear\")\n",
    "axs[0].axis(\"off\")\n",
    "axs[0].set_title(\"üî¥ Comentarios t√≥xicos (sin stopwords)\")\n",
    "\n",
    "axs[1].imshow(wc_nontoxico, interpolation=\"bilinear\")\n",
    "axs[1].axis(\"off\")\n",
    "axs[1].set_title(\"üü¢ Comentarios no t√≥xicos (sin stopwords)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### WordClouds sin palabras vac√≠as (stopwords)\n",
    "\n",
    "Las siguientes nubes de palabras muestran los t√©rminos m√°s repetidos en los comentarios **t√≥xicos** y **no t√≥xicos**, tras eliminar las palabras vac√≠as t√≠picas del ingl√©s (como ‚Äúthe‚Äù, ‚Äúand‚Äù, ‚Äúis‚Äù‚Ä¶).\n",
    "\n",
    "#### ¬øQu√© observamos?\n",
    "- En los comentarios t√≥xicos aparecen con m√°s frecuencia palabras como **‚Äúfuck‚Äù**, lo que indica un tono agresivo.\n",
    "- Tambi√©n se observan t√©rminos raciales y relacionados con el orden p√∫blico (**black, white, police**) en ambos grupos, lo que sugiere que el contexto es similar, pero el uso del lenguaje es lo que cambia.\n",
    "\n",
    "Esta visualizaci√≥n permite a cualquier lector, incluso sin formaci√≥n t√©cnica, entender mejor el tipo de lenguaje que caracteriza cada grupo de comentarios.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
