<img src="images/logo.png"></img>

# Proyecto X de NLP: Analisis de Sentimientos para Factor√≠a F5 por el grupo 1.

Andrea Alonso

Mariela Adimari

C√©sar Mercado

Alla Haruty

## Prop√≥sito y Alcance

Este proyecto es una aplicaci√≥n web impulsada por aprendizaje autom√°tico, dise√±ada para analizar texto y detectar contenido t√≥xico. Ofrece dos funcionalidades principales:

- **An√°lisis de comentarios individuales:** Mediante la inserci√≥n de un texto.
- **An√°lisis masivo de comentarios de videos de YouTube:** Mediante la inserci√≥n de la URL del v√≠deo de YouTube

Los resultados se almacenan en una base de datos persistente en Supabase y se utilizar√°n posteriormente para el reentrenamiento del modelo.

---

## Arquitectura del Sistema

El sistema sigue una arquitectura de tres capas:

1. **Capa de Presentaci√≥n**: Frontend construido con Next.js.
2. **Capa de Aplicaci√≥n**: Backend construido con FastAPI.
3. **Capa de Datos**: Base de datos Supabase con mecanismo de respaldo local en caso que la conexi√≥n no sea exitosa.

### Componentes Principales

- **Frontend (Next.js)**: Interfaz de usuario y cliente de API.
- **Backend (FastAPI)**:
  - `predictions.py`: Ruta principal para predicciones.
  - `model_loader.py`: Carga del modelo ML y vectorizador.
  - `extract_youtube_comments.py`: Extracci√≥n de comentarios de YouTube.
  - `fallback.py`: Mecanismo de respaldo en caso de fallo en base de datos.
  - `retry_pending.py`: Funci√≥n para subir a la base de datos los datos que tenemos en local.
- **Persistencia de Datos**:
  - Base de datos Supabase.
  - Archivo local `pending_predictions.json` como respaldo si falla la conexi√≥n con Supabase.

---

## Modelos de Machine Learning

- **Vectorizador TF-IDF**: `vectorizer_toxicidad_final.pkl`
- **Clasificador XGBoost**: `modelo_toxicidad_xgboost_final.pkl`

Proceso de predicci√≥n:
1. Entrada de texto √≥ URL del v√≠deo.
2. Vectorizaci√≥n con TF-IDF.
3. Clasificaci√≥n con XGBoost.
4. Salida: Etiqueta de toxicidad y puntaje.

---

## Endpoints de la API

| Endpoint                 | M√©todo | Descripci√≥n                               |
|--------------------------|--------|-------------------------------------------|
| `/predict`               | POST   | An√°lisis de un comentario individual.     |
| `/predict/youtube`      | POST   | An√°lisis de comentarios de un video.      |
| `/history`              | GET    | Recupera historial de predicciones.       |

### Flujo de Datos

- **Entrada**: Comentario o URL de video de YouTube.
- **Procesamiento**: Extracci√≥n ‚Üí Traducci√≥n (si aplica) ‚Üí Predicci√≥n.
- **Salida**: Puntaje de toxicidad, etiqueta, y versi√≥n del modelo, guardado en base de datos o local.

---

## Estrategia de Persistencia

- **Primario**: Inserciones en Supabase.
- **Secundario (Fallback)**:
  - En caso de error de conexi√≥n, los datos se almacenan en `pending_predictions.json`.
  - Se reintentan manualmente cuando se restablece la conexi√≥n (`retry_pending.py`).

---

## Procesamiento de Comentarios de YouTube

1. URL del video como entrada.
2. `extract_comments()` extrae comentarios.
3. `translate_if_needed()` traduce si es necesario.
4. Los comentarios se procesan en lote por el modelo.
5. Se devuelve un resumen con toxicidad promedio.

---

## Dependencias Principales

- [`FastAPI`](https://fastapi.tiangolo.com/) - Backend web framework.
- [`scikit-learn`](https://scikit-learn.org/) - Vectorizaci√≥n TF-IDF.
- [`xgboost`](https://xgboost.readthedocs.io/) - Clasificaci√≥n ML.
- [`supabase`](https://supabase.com/) - Base de datos en la nube.
- [`youtube-comment-downloader`](https://pypi.org/project/youtube-comment-downloader/) - Extracci√≥n de comentarios.
- [`deep-translator`](https://pypi.org/project/deep-translator/) - Traducci√≥n multiling√ºe.

---

## Manejo de Errores y Resiliencia

- **Respaldo Local**: Fallback autom√°tico si Supabase no est√° disponible.
- **Reintentos**: Los datos pendientes se reintentan subir manualmente.
- **Validaci√≥n de Entrada**: Modelos Pydantic garantizan datos v√°lidos.
- **Registro de Errores**: Se registran excepciones para depuraci√≥n.

---

## üìÅ Estructura del repositorio

<img src="images/tree.png" width="300"></img>


## Dockerizaci√≥n

Tanto el Backend como el Frontend est√°n dockerizados y la im√°gen est√° subida a Dockerhub y se pueden descargar con el siguiente comando:

- **Frontend image:** `docker push allaharuty/px-g1-frontend:tagname`

- **Backend image:** `docker push allaharuty/px-g1-app:tagname`


## Despliegue

Adem√°s, se han desplegado en render los 2 servicios:

- [Backend](https://backend-sentimientos.onrender.com/)

- [Frontend](https://frontend-sentimientos.onrender.com)


## Pon en marcha el proyecto

1. Abre un terminal
2. ```git clone https://github.com/Bootcamp-IA-P4/PX-G1.git```
3. Pega el .env que se te ha proporcionado
4. ```pip install -r requirements.txt```
5. ```uvicorn fast_api.main:app --reload```
6. Abre nuevo terminal
7. ```cd front```
8. ```npm install```
9. ```npm run dev```

Ya puedes acceder al proyecto:

- Puerto backend: `http://127.0.0.1:8000`
- Puerto frontend: `http://localhost:3000`


![Video Demo](images/demo.gif)


## Test unitarios y loggers

Se integran **8 unittests** divididos en 5 archivos que comprueban el buen funcionamiento del backend y loggers que llevan la trazabilidad de toda la aplicaci√≥n y se guardan en logs/logs.log

<img src="images/tests-tree.png" width="200"></img>
<img src="images/tests-passed.png" width="500"></img>

Para probarlo desde la ra√≠z del repositorio:

```
pip install -r requirements.txt
pytest
```

## Diagrama de arquitectura

<img src="images/diagrama.png" width="800"></img>

# Metodolog√≠a trabajada y equipo

El equipo ha trabajado en conjunto en los primeros pasos como el An√°lisis Exploratorio de Datos y el entrenamiento del Modelo adecuado y tras una comparaci√≥n de los resultados de cada integrante, se ha realizado un EDA en conjunto extrayendo todo lo com√∫n e interesante y se ha escogido el modelo con las mejores m√©tricas.


TODO: Meter m√©tricas del modelo, el nombrel algoritmo, t√©cnicas, etc...

Se pueden ver los EDAs realizados en la carpeta EDAs de la rama [feature/EDA](https://github.com/Bootcamp-IA-P4/PX-G1/tree/feature/EDA) donde cada integrante tiene su propio archivo. 

Y se pueden ver los entrenamientos de los modelos en la carpeta models en la rama [feature/model](https://github.com/Bootcamp-IA-P4/PX-G1/tree/feature/model) tambi√©n con sus respectivos archivos.

- [Para ver el EDA final haz click aqu√≠](https://github.com/Bootcamp-IA-P4/PX-G1/blob/feature/EDA/EDAs/FINAL-EDA.ipynb) üìå

- [Para ver el entrenamiento del modelo final haz click aqu√≠](https://github.com/Bootcamp-IA-P4/PX-G1/blob/feature/model/models/Marie-models.ipynb) üìå

Adem√°s, para mejorar la explicabilidad de nuestro modelo y comprender c√≥mo influye cada caracter√≠stica del conjunto de datos en sus predicciones, hemos creado un archivo llamado [`shap_explainer.ipynb`](https://github.com/Bootcamp-IA-P4/PX-G1/blob/feature/model/models/shap_explainer.ipynb) üìå



## Deepwiki

Puedes saber m√°s sobre el proyecto en [este link de Deepwiki.](https://deepwiki.com/Bootcamp-IA-P4/PX-G1/1-overview)


