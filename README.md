![Logo](images/logo.png)

# Proyecto X de NLP: An√°lisis de Sentimientos para Factor√≠a F5 por el grupo 1.

Andrea Alonso

Mariela Adimari

C√©sar Mercado

Alla Haruty

## Prop√≥sito y Alcance

Este proyecto es una aplicaci√≥n web impulsada por aprendizaje autom√°tico, dise√±ada para analizar texto y detectar contenido t√≥xico. Ofrece dos funcionalidades principales:

- **An√°lisis de comentarios individuales:** Mediante la inserci√≥n de un texto.
- **An√°lisis masivo de comentarios de videos de YouTube:** Mediante la inserci√≥n de la URL del v√≠deo de YouTube

Los resultados se almacenan en una base de datos persistente en Supabase y se utilizar√°n posteriormente para el reentrenamiento del modelo.

---

## Arquitectura del Sistema

El sistema sigue una arquitectura de tres capas:

1. **Capa de Presentaci√≥n**: Frontend construido con Next.js.
2. **Capa de Aplicaci√≥n**: Backend construido con FastAPI.
3. **Capa de Datos**: Base de datos Supabase con mecanismo de respaldo local en caso que la conexi√≥n no sea exitosa.

### Componentes Principales

- **Frontend (Next.js)**: Interfaz de usuario y cliente de API.
- **Backend (FastAPI)**:
  - `predictions.py`: Ruta principal para predicciones.
  - `model_loader.py`: Carga del modelo ML y vectorizador.
  - `extract_youtube_comments.py`: Extracci√≥n de comentarios de YouTube.
  - `fallback.py`: Mecanismo de respaldo en caso de fallo en base de datos.
  - `retry_pending.py`: Funci√≥n para subir a la base de datos los datos que tenemos en local.
- **Persistencia de Datos**:
  - Base de datos Supabase.
  - Archivo local `pending_predictions.json` como respaldo si falla la conexi√≥n con Supabase.

---

## Modelos de Machine Learning

- **Vectorizador TF-IDF**: `vectorizer_toxicidad_final.pkl`
- **Clasificador XGBoost**: `modelo_toxicidad_xgboost_final.pkl`

Proceso de predicci√≥n:
1. Entrada de texto √≥ URL del v√≠deo.
2. Vectorizaci√≥n con TF-IDF.
3. Clasificaci√≥n con XGBoost.
4. Salida: Etiqueta de toxicidad y puntaje.

---

## Endpoints de la API

| Endpoint                 | M√©todo | Descripci√≥n                               |
|--------------------------|--------|-------------------------------------------|
| `/predict`               | POST   | An√°lisis de un comentario individual.     |
| `/predict/youtube`      | POST   | An√°lisis de comentarios de un video.      |
| `/history`              | GET    | Recupera historial de predicciones.       |

### Flujo de Datos

- **Entrada**: Comentario o URL de video de YouTube.
- **Procesamiento**: Extracci√≥n ‚Üí Traducci√≥n (si aplica) ‚Üí Predicci√≥n.
- **Salida**: Puntaje de toxicidad, etiqueta, y versi√≥n del modelo, guardado en base de datos o local.

---

## Estrategia de Persistencia

- **Primario**: Inserciones en Supabase.
- **Secundario (Fallback)**:
  - En caso de error de conexi√≥n, los datos se almacenan en `pending_predictions.json`.
  - Se reintentan manualmente cuando se restablece la conexi√≥n (`retry_pending.py`).

---

## Procesamiento de Comentarios de YouTube

1. URL del video como entrada.
2. `extract_comments()` extrae comentarios.
3. `translate_if_needed()` traduce si es necesario.
4. Los comentarios se procesan en lote por el modelo.
5. Se devuelve un resumen con toxicidad promedio.

---

## Dependencias Principales

- [`FastAPI`](https://fastapi.tiangolo.com/) - Backend web framework.
- [`scikit-learn`](https://scikit-learn.org/) - Vectorizaci√≥n TF-IDF.
- [`xgboost`](https://xgboost.readthedocs.io/) - Clasificaci√≥n ML.
- [`supabase`](https://supabase.com/) - Base de datos en la nube.
- [`youtube-comment-downloader`](https://pypi.org/project/youtube-comment-downloader/) - Extracci√≥n de comentarios.
- [`deep-translator`](https://pypi.org/project/deep-translator/) - Traducci√≥n multiling√ºe.

---

## Manejo de Errores y Resiliencia

- **Respaldo Local**: Fallback autom√°tico si Supabase no est√° disponible.
- **Reintentos**: Los datos pendientes se reintentan subir manualmente.
- **Validaci√≥n de Entrada**: Modelos Pydantic garantizan datos v√°lidos.
- **Registro de Errores**: Se registran excepciones para depuraci√≥n.

---

## üìÅ Estructura del repositorio

<img src="images/tree.png" width="300"></img>


## Dockerizaci√≥n

Tanto el Backend como el Frontend est√°n dockerizados y la imagen est√° subida a Dockerhub y se pueden descargar con el siguiente comando:

- **Imagen Frontend:** `docker push allaharuty/px-g1-frontend:tagname`

- **Imagen Backend:** `docker push allaharuty/px-g1-app:tagname`

Ver c√≥digo fuente en [la rama feature/docker.](https://github.com/Bootcamp-IA-P4/PX-G1/tree/feature/docker)

## Despliegue

Adem√°s, se han desplegado en render los 2 servicios:

- [Backend](https://backend-sentimientos.onrender.com/)

- [Frontend](https://frontend-sentimientos.onrender.com)


## Pon en marcha el proyecto

1. Abre un terminal
2. ```git clone https://github.com/Bootcamp-IA-P4/PX-G1.git```
3. Pega el .env que se te ha proporcionado
4. ```pip install -r requirements.txt```
5. ```uvicorn fast_api.main:app --reload```
6. Abre nuevo terminal
7. ```cd front```
8. ```npm install```
9. ```npm run dev```

Ya puedes acceder al proyecto:

- Puerto backend: `http://127.0.0.1:8000`
- Puerto frontend: `http://localhost:3000`


![Video Demo](images/demo.gif)


## Test unitarios y loggers

Se integran **8 unittests** divididos en 5 archivos que comprueban el buen funcionamiento del backend y loggers que llevan la trazabilidad de toda la aplicaci√≥n y se guardan en logs/logs.log

<img src="images/tests-tree.png" width="200"></img>
<img src="images/tests-passed.png" width="500"></img>

Para probarlo desde la ra√≠z del repositorio:

```
pip install -r requirements.txt
pytest
```

## Diagrama de arquitectura

<img src="images/diagrama.png" width="800"></img>

# Metodolog√≠a trabajada y equipo

El equipo ha trabajado en conjunto en los primeros pasos como el An√°lisis Exploratorio de Datos y el entrenamiento del Modelo adecuado y tras una comparaci√≥n de los resultados de cada integrante, se ha realizado un EDA en conjunto extrayendo todo lo com√∫n e interesante y se ha escogido el modelo con las mejores m√©tricas.

## Nuestro modelo elegido fue XGBoost:
Tras la optimizacion de hiperparametros con Optuna nos dio las siguientes metricas
![alt text](<Captura de pantalla 2025-07-14 111801.png>)

### üéØ F1 Score

| Tipo       | Valor          | Significado                                                                                                   |
| ---------- | -------------- | ------------------------------------------------------------------------------------------------------------- |
| `Train F1` | 0.9420         | Rendimiento en el conjunto de entrenamiento. Muy alto: el modelo se ajusta bien a los datos de entrenamiento. |
| `CV F1`    | 0.8574 ¬±0.0073 | Promedio del F1 score en validaci√≥n cruzada. Buena generalizaci√≥n.                                            |
| `Test F1`  | 0.8977         | Rendimiento en el conjunto de test. Algo m√°s bajo que `Train`, lo cual es esperable.                          |

üîç Gap overfitting F1: 0.0443

    Diferencia entre Train F1 y Test F1. Un gap peque√±o (<0.05) indica que no hay sobreajuste severo.

### üìâ LogLoss (Logarithmic Loss)
Esta m√©trica penaliza m√°s cuando el modelo est√° muy seguro y se equivoca. Cuanto m√°s bajo, mejor.

| Tipo                              | Valor                                          | Significado                                    |
| --------------------------------- | ---------------------------------------------- | ---------------------------------------------- |
| `Train LogLoss`                   | 0.2531                                         | Error promedio de predicci√≥n en entrenamiento. |
| `Test LogLoss`                    | 0.3083                                         | Error promedio en test.                        |
| `Gap overfitting LogLoss: 0.0552` | Diferencia entre ambos. Aceptable si es < 0.1. |                                                |

### üèÅ Modelo final

- **Train F1:** 0.9427

- **Test F1:** 0.8958

- **CV F1:** 0.854 ¬±0.014 (estable)

- **Overfitting gap F1:** 0.0469 ‚Üí Buena generalizaci√≥n

- **Train LogLoss:** 0.2552 | Test LogLoss: 0.3093 

- **Overfitting gap LogLoss:** 0.0541 ‚Üí Bajo

### üìå Conclusi√≥n:
El modelo est√° bien entrenado, con buen rendimiento en todos los conjuntos y sin se√±ales graves de overfitting.

Se pueden ver los EDAs realizados en la carpeta EDAs de la rama [feature/EDA](https://github.com/Bootcamp-IA-P4/PX-G1/tree/feature/EDA) donde cada integrante tiene su propio archivo. 

Y se pueden ver los entrenamientos de los modelos en la carpeta models en la rama [feature/model](https://github.com/Bootcamp-IA-P4/PX-G1/tree/feature/model) tambi√©n con sus respectivos archivos.

- [Para ver el EDA final haz click aqu√≠](https://github.com/Bootcamp-IA-P4/PX-G1/blob/feature/EDA/EDAs/FINAL-EDA.ipynb) üìå

- [Para ver el entrenamiento del modelo final haz click aqu√≠](https://github.com/Bootcamp-IA-P4/PX-G1/blob/feature/model/models/Marie-models.ipynb) üìå

Adem√°s, para mejorar la explicabilidad de nuestro modelo y comprender c√≥mo influye cada caracter√≠stica del conjunto de datos en sus predicciones, hemos creado un archivo llamado [`shap_explainer.ipynb`](https://github.com/Bootcamp-IA-P4/PX-G1/blob/feature/model/models/shap_explainer.ipynb) üìå



## Deepwiki

Puedes saber m√°s sobre el proyecto en [este link de Deepwiki.](https://deepwiki.com/Bootcamp-IA-P4/PX-G1/1-overview)


