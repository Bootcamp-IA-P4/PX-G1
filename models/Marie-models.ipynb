{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# üéØ Objetivo: Detectar toxicidad con datos aumentados\n",
    "\n",
    "## üìã Estrategia:\n",
    "### - Eliminar columnas desbalanceadas\n",
    "### - Aplicar Data Augmentation con traducci√≥n\n",
    "### - Preprocesar texto eficientemente\n",
    "### - Entrenar XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Procesamiento de texto\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score \n",
    "import xgboost as xgb\n",
    "\n",
    "# Para augmentaci√≥n simple\n",
    "import random\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Persistencia\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuraci√≥n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Cargar datos y an√°lisis inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../data/youtoxic_english_1000.csv')\n",
    "print(f\"‚úÖ Dataset original: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "\n",
    "# Columnas de toxicidad\n",
    "columnas_toxicidad = ['IsAbusive', 'IsThreat', 'IsProvocative', 'IsObscene', \n",
    "                      'IsHatespeech', 'IsRacist', 'IsNationalist', 'IsSexist', \n",
    "                      'IsHomophobic', 'IsReligiousHate', 'IsRadicalism']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# 2. IDENTIFICAR Y ELIMINAR COLUMNAS DESBALANCEADAS="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç Analizando balance de columnas...\")\n",
    "\n",
    "# Calcular balance\n",
    "balance = {}\n",
    "UMBRAL = 5.0  # 5% m√≠nimo\n",
    "\n",
    "for col in columnas_toxicidad:\n",
    "    porcentaje = (df[col].sum() / len(df)) * 100\n",
    "    balance[col] = porcentaje\n",
    "    estado = \"‚úÖ Mantener\" if porcentaje >= UMBRAL else \"‚ùå Eliminar\"\n",
    "    print(f\"{col:20} -> {porcentaje:5.1f}% {estado}\")\n",
    "\n",
    "# Seleccionar solo columnas balanceadas\n",
    "columnas_mantener = [col for col in columnas_toxicidad if balance[col] >= UMBRAL]\n",
    "columnas_eliminar = [col for col in columnas_toxicidad if balance[col] < UMBRAL]\n",
    "\n",
    "print(f\"\\nüìä Resumen:\")\n",
    "print(f\"   - Columnas a mantener: {len(columnas_mantener)}\")\n",
    "print(f\"   - Columnas a eliminar: {len(columnas_eliminar)}\")\n",
    "\n",
    "# Crear etiqueta binaria solo con columnas balanceadas\n",
    "df['toxic_binary'] = (df[columnas_mantener].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "# Eliminar columnas desbalanceadas del dataset\n",
    "df = df.drop(columns=columnas_eliminar)\n",
    "\n",
    "print(f\"\\n‚úÖ Nueva distribuci√≥n de toxicidad:\")\n",
    "print(df['toxic_binary'].value_counts())\n",
    "print(f\"Porcentaje t√≥xico: {df['toxic_binary'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# 3. PREPROCESAMIENTO DE TEXTO EFICIENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüßπ Preparando funciones de preprocesamiento...\")\n",
    "\n",
    "# Inicializar herramientas\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    \"\"\"Limpieza r√°pida y eficiente del texto\"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    \n",
    "    texto = str(texto).lower()\n",
    "    texto = re.sub(r'@\\w+|http\\S+|www\\S+', '', texto)  # URLs y menciones\n",
    "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)  # Solo letras\n",
    "    texto = ' '.join(texto.split())  # Espacios extras\n",
    "    \n",
    "    return texto\n",
    "\n",
    "def procesar_texto(texto):\n",
    "    \"\"\"Procesamiento completo con lemmatizaci√≥n\"\"\"\n",
    "    # Tokenizar\n",
    "    palabras = word_tokenize(texto)\n",
    "    \n",
    "    # Filtrar stopwords y palabras cortas\n",
    "    palabras = [lemmatizer.lemmatize(p) for p in palabras \n",
    "                if p not in stop_words and len(p) > 2]\n",
    "    \n",
    "    return ' '.join(palabras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# 4. DATA AUGMENTATION SIN APIS EXTERNAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüåê Configurando Data Augmentation...\")\n",
    "\n",
    "def augmentar_texto_avanzado(texto):\n",
    "    \"\"\"\n",
    "    Aumenta datos usando t√©cnicas que no requieren APIs externas.\n",
    "    Genera m√∫ltiples variaciones del texto original.\n",
    "    \"\"\"\n",
    "    variaciones = []\n",
    "    \n",
    "    # 1. Reemplazo de sin√≥nimos comunes\n",
    "    sinonimos = {\n",
    "        'hate': ['despise', 'loathe', 'detest'],\n",
    "        'stupid': ['dumb', 'idiotic', 'foolish', 'moronic'],\n",
    "        'bad': ['terrible', 'awful', 'horrible'],\n",
    "        'good': ['great', 'excellent', 'wonderful'],\n",
    "        'idiot': ['fool', 'moron', 'imbecile'],\n",
    "        'ugly': ['hideous', 'repulsive', 'disgusting'],\n",
    "        'fat': ['obese', 'overweight', 'heavy'],\n",
    "        'kill': ['murder', 'destroy', 'eliminate'],\n",
    "        'die': ['perish', 'expire', 'pass away'],\n",
    "        'trash': ['garbage', 'rubbish', 'waste'],\n",
    "        'suck': ['terrible', 'awful', 'horrible'],\n",
    "        'dumb': ['stupid', 'idiotic', 'brainless']\n",
    "    }\n",
    "    \n",
    "    # Variaci√≥n 1: Reemplazar sin√≥nimos\n",
    "    texto_sinonimos = texto.lower()\n",
    "    for palabra, alternativas in sinonimos.items():\n",
    "        if palabra in texto_sinonimos:\n",
    "            for alternativa in alternativas[:2]:  # Usar m√°ximo 2 sin√≥nimos\n",
    "                nuevo_texto = texto_sinonimos.replace(palabra, alternativa)\n",
    "                if nuevo_texto != texto_sinonimos:\n",
    "                    variaciones.append(nuevo_texto)\n",
    "    \n",
    "    # 2. Inserci√≥n de ruido controlado\n",
    "    palabras = texto.split()\n",
    "    if len(palabras) > 5:\n",
    "        # Variaci√≥n 2: Eliminar palabras no esenciales\n",
    "        palabras_importantes = [p for p in palabras if len(p) > 3]\n",
    "        if len(palabras_importantes) > 3:\n",
    "            variaciones.append(' '.join(palabras_importantes))\n",
    "        \n",
    "        # Variaci√≥n 3: Cambiar orden de frases\n",
    "        if '.' in texto or '!' in texto or '?' in texto:\n",
    "            import re\n",
    "            frases = re.split(r'[.!?]+', texto)\n",
    "            frases = [f.strip() for f in frases if f.strip()]\n",
    "            if len(frases) > 1:\n",
    "                random.shuffle(frases)\n",
    "                variaciones.append('. '.join(frases) + '.')\n",
    "    \n",
    "    # 3. Par√°frasis simple usando TextBlob (sin traducci√≥n)\n",
    "    try:\n",
    "        blob = TextBlob(texto)\n",
    "        # Cambiar tiempos verbales si es posible\n",
    "        if blob.tags:\n",
    "            texto_modificado = str(blob)\n",
    "            # Intercambiar algunas palabras comunes\n",
    "            intercambios = [\n",
    "                ('you are', \"you're\"), (\"you're\", 'you are'),\n",
    "                ('i am', \"i'm\"), (\"i'm\", 'i am'),\n",
    "                ('do not', \"don't\"), (\"don't\", 'do not'),\n",
    "                ('will not', \"won't\"), (\"won't\", 'will not')\n",
    "            ]\n",
    "            for original, reemplazo in intercambios:\n",
    "                if original in texto_modificado.lower():\n",
    "                    texto_modificado = texto_modificado.lower().replace(original, reemplazo)\n",
    "                    if texto_modificado != texto.lower():\n",
    "                        variaciones.append(texto_modificado)\n",
    "                        break\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 4. Agregar/quitar puntuaci√≥n excesiva (com√∫n en comentarios t√≥xicos)\n",
    "    if any(c in texto for c in ['!', '?', '...']):\n",
    "        # Reducir puntuaci√≥n\n",
    "        texto_reducido = re.sub(r'[!]+', '!', texto)\n",
    "        texto_reducido = re.sub(r'[?]+', '?', texto_reducido)\n",
    "        texto_reducido = re.sub(r'\\.{3,}', '...', texto_reducido)\n",
    "        if texto_reducido != texto:\n",
    "            variaciones.append(texto_reducido)\n",
    "        \n",
    "        # Aumentar puntuaci√≥n (para comentarios t√≥xicos)\n",
    "        texto_aumentado = texto.replace('!', '!!!')\n",
    "        texto_aumentado = texto_aumentado.replace('?', '???')\n",
    "        if texto_aumentado != texto:\n",
    "            variaciones.append(texto_aumentado)\n",
    "    \n",
    "    # Eliminar duplicados y retornar\n",
    "    return list(set(variaciones))[:3]  # M√°ximo 3 variaciones por texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# 5. APLICAR AUGMENTATION A COMENTARIOS T√ìXICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîÑ Aplicando Data Augmentation a comentarios t√≥xicos...\")\n",
    "\n",
    "# Separar comentarios t√≥xicos para aumentar\n",
    "df_toxicos = df[df['toxic_binary'] == 1].copy()\n",
    "df_no_toxicos = df[df['toxic_binary'] == 0].copy()\n",
    "\n",
    "print(f\"Comentarios t√≥xicos originales: {len(df_toxicos)}\")\n",
    "print(f\"Comentarios no t√≥xicos: {len(df_no_toxicos)}\")\n",
    "\n",
    "# Aplicar augmentation\n",
    "comentarios_aumentados = []\n",
    "etiquetas_aumentadas = []\n",
    "contador = 0\n",
    "\n",
    "for idx, row in df_toxicos.iterrows():\n",
    "    texto_limpio = limpiar_texto(row['Text'])\n",
    "    \n",
    "    # Generar variaciones\n",
    "    variaciones = augmentar_texto_avanzado(texto_limpio)\n",
    "    \n",
    "    for variacion in variaciones:\n",
    "        if variacion and len(variacion) > 10:  # Solo agregar si tiene contenido\n",
    "            comentarios_aumentados.append(variacion)\n",
    "            etiquetas_aumentadas.append(1)\n",
    "            contador += 1\n",
    "    \n",
    "    # Mostrar progreso\n",
    "    if idx % 50 == 0:\n",
    "        print(f\"   Procesados: {idx}/{len(df_toxicos)} - Generados: {contador} nuevos\")\n",
    "\n",
    "# Crear DataFrame con datos aumentados\n",
    "df_aumentados = pd.DataFrame({\n",
    "    'Text': comentarios_aumentados,\n",
    "    'toxic_binary': etiquetas_aumentadas\n",
    "})\n",
    "\n",
    "print(f\"\\n‚úÖ Comentarios t√≥xicos generados: {len(df_aumentados)}\")\n",
    "\n",
    "# Combinar datasets\n",
    "df_final = pd.concat([\n",
    "    df[['Text', 'toxic_binary']],\n",
    "    df_aumentados\n",
    "], ignore_index=True)\n",
    "\n",
    "# Mezclar aleatoriamente\n",
    "df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nüìä Dataset final:\")\n",
    "print(f\"   - Total comentarios: {len(df_final)}\")\n",
    "print(f\"   - T√≥xicos: {df_final['toxic_binary'].sum()}\")\n",
    "print(f\"   - No t√≥xicos: {len(df_final) - df_final['toxic_binary'].sum()}\")\n",
    "print(f\"   - Balance: {df_final['toxic_binary'].mean()*100:.1f}% t√≥xicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# 6. PREPROCESAR TODO EL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚è≥ Preprocesando todos los textos...\")\n",
    "\n",
    "# Aplicar limpieza y procesamiento\n",
    "df_final['texto_limpio'] = df_final['Text'].apply(limpiar_texto)\n",
    "df_final['texto_procesado'] = df_final['texto_limpio'].apply(procesar_texto)\n",
    "\n",
    "# Eliminar filas vac√≠as\n",
    "df_final = df_final[df_final['texto_procesado'].str.len() > 0]\n",
    "\n",
    "print(f\"‚úÖ Textos procesados: {len(df_final)}\")\n",
    "\n",
    "# Guardar dataset procesado\n",
    "df_final.to_csv('../data/dataset_toxicidad_aumentado.csv', index=False)\n",
    "print(\"üíæ Dataset guardado como: ../data/dataset_toxicidad_aumentado.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# 7. VISUALIZACI√ìN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Balance de clases\n",
    "df_final['toxic_binary'].value_counts().plot(kind='bar', ax=axes[0], \n",
    "                                            color=['lightgreen', 'salmon'])\n",
    "axes[0].set_title('Distribuci√≥n de Clases (Con Augmentation)')\n",
    "axes[0].set_xlabel('Clase')\n",
    "axes[0].set_ylabel('Cantidad')\n",
    "axes[0].set_xticklabels(['No T√≥xico', 'T√≥xico'], rotation=0)\n",
    "\n",
    "# Longitud de comentarios\n",
    "df_final['longitud'] = df_final['texto_procesado'].str.split().str.len()\n",
    "df_final.boxplot(column='longitud', by='toxic_binary', ax=axes[1])\n",
    "axes[1].set_title('Longitud de Comentarios por Clase')\n",
    "axes[1].set_xlabel('T√≥xico')\n",
    "axes[1].set_ylabel('N√∫mero de palabras')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# WORDCLOUDS COMPARATIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä WORDCLOUDS COMPARATIVOS\")\n",
    "\n",
    "# Separar textos por categor√≠a usando los datos procesados\n",
    "textos_toxicos = df_final[df_final['toxic_binary'] == 1]['texto_procesado']\n",
    "textos_no_toxicos = df_final[df_final['toxic_binary'] == 0]['texto_procesado']\n",
    "\n",
    "print(f\"   ‚Ä¢ Comentarios t√≥xicos para WordCloud: {len(textos_toxicos)}\")\n",
    "print(f\"   ‚Ä¢ Comentarios no t√≥xicos para WordCloud: {len(textos_no_toxicos)}\")\n",
    "\n",
    "# Combinar textos por categor√≠a\n",
    "texto_toxico_combinado = ' '.join(textos_toxicos.dropna())\n",
    "texto_no_toxico_combinado = ' '.join(textos_no_toxicos.dropna())\n",
    "\n",
    "print(f\"   ‚Ä¢ Palabras en corpus t√≥xico: {len(texto_toxico_combinado.split())}\")\n",
    "print(f\"   ‚Ä¢ Palabras en corpus no t√≥xico: {len(texto_no_toxico_combinado.split())}\")\n",
    "\n",
    "# Verificar que tenemos suficiente texto\n",
    "if len(texto_toxico_combinado.split()) < 10:\n",
    "    print(\"‚ö†Ô∏è Advertencia: Poco texto t√≥xico disponible para WordCloud\")\n",
    "if len(texto_no_toxico_combinado.split()) < 10:\n",
    "    print(\"‚ö†Ô∏è Advertencia: Poco texto no t√≥xico disponible para WordCloud\")\n",
    "\n",
    "# Generar WordClouds\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Configuraci√≥n com√∫n para ambos WordClouds\n",
    "wordcloud_config = {\n",
    "    'width': 800,\n",
    "    'height': 400,\n",
    "    'background_color': 'white',\n",
    "    'max_words': 100,\n",
    "    'relative_scaling': 0.5,\n",
    "    'stopwords': stop_words,  # Usar las mismas stopwords del preprocesamiento\n",
    "    'collocation_threshold': 10\n",
    "}\n",
    "\n",
    "# WordCloud para comentarios t√≥xicos\n",
    "if len(texto_toxico_combinado.strip()) > 0:\n",
    "    wordcloud_toxico = WordCloud(\n",
    "        **wordcloud_config,\n",
    "        colormap='Reds'\n",
    "    ).generate(texto_toxico_combinado)\n",
    "    \n",
    "    axes[0].imshow(wordcloud_toxico, interpolation='bilinear')\n",
    "    axes[0].set_title('WordCloud - Comentarios T√ìXICOS', fontweight='bold', fontsize=16, color='darkred')\n",
    "    axes[0].axis('off')\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'No hay suficiente\\ntexto t√≥xico', \n",
    "                ha='center', va='center', transform=axes[0].transAxes, fontsize=16)\n",
    "    axes[0].set_title('WordCloud - Comentarios T√ìXICOS', fontweight='bold', fontsize=16, color='darkred')\n",
    "\n",
    "# WordCloud para comentarios no t√≥xicos\n",
    "if len(texto_no_toxico_combinado.strip()) > 0:\n",
    "    wordcloud_no_toxico = WordCloud(\n",
    "        **wordcloud_config,\n",
    "        colormap='Greens'\n",
    "    ).generate(texto_no_toxico_combinado)\n",
    "    \n",
    "    axes[1].imshow(wordcloud_no_toxico, interpolation='bilinear')\n",
    "    axes[1].set_title('WordCloud - Comentarios NO T√ìXICOS', fontweight='bold', fontsize=16, color='darkgreen')\n",
    "    axes[1].axis('off')\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'No hay suficiente\\ntexto no t√≥xico', \n",
    "                ha='center', va='center', transform=axes[1].transAxes, fontsize=16)\n",
    "    axes[1].set_title('WordCloud - Comentarios NO T√ìXICOS', fontweight='bold', fontsize=16, color='darkgreen')\n",
    "\n",
    "plt.suptitle('An√°lisis Visual del Vocabulario por Categor√≠a', fontsize=20, fontweight='bold', y=0.95)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# 8. PREPARACI√ìN PARA MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ Preparando datos para entrenamiento...\")\n",
    "\n",
    "# Features y target\n",
    "X = df_final['texto_procesado']\n",
    "y = df_final['toxic_binary']\n",
    "\n",
    "# Divisi√≥n estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"üìä Divisi√≥n de datos:\")\n",
    "print(f\"   - Entrenamiento: {len(X_train)} ({y_train.mean()*100:.1f}% t√≥xicos)\")\n",
    "print(f\"   - Prueba: {len(X_test)} ({y_test.mean()*100:.1f}% t√≥xicos)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# 9. VECTORIZACI√ìN OPTIMIZADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüî¢ Vectorizando con TF-IDF...\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=2000,      # M√°s features por m√°s datos\n",
    "    ngram_range=(1, 3),     # Incluir trigramas\n",
    "    min_df=2,               # M√≠nima frecuencia\n",
    "    max_df=0.95,            # M√°xima frecuencia\n",
    "    sublinear_tf=True,      # Escalado logar√≠tmico\n",
    "    use_idf=True,           # IDF para ponderar importancia\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"‚úÖ Forma de datos vectorizados: {X_train_vec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "# 10. ENTRENAMIENTO DE XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüöÄ Entrenando XGBoost optimizado...\")\n",
    "\n",
    "# Calcular peso de clases para balanceo\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Modelo XGBoost con hiperpar√°metros optimizados\n",
    "modelo = xgb.XGBClassifier(\n",
    "    # Par√°metros b√°sicos\n",
    "    n_estimators=300,           # N√∫mero de √°rboles\n",
    "    max_depth=6,                # Profundidad m√°xima\n",
    "    learning_rate=0.1,          # Tasa de aprendizaje\n",
    "    \n",
    "    # Control de overfitting\n",
    "    subsample=0.8,              # Submuestreo de filas\n",
    "    colsample_bytree=0.8,       # Submuestreo de columnas\n",
    "    reg_alpha=0.1,              # Regularizaci√≥n L1\n",
    "    reg_lambda=1.0,             # Regularizaci√≥n L2\n",
    "    \n",
    "    # Balanceo de clases\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    \n",
    "    # Otros par√°metros\n",
    "    objective='binary:logistic',\n",
    "    eval_metric=['error', 'logloss'],  # M√©tricas de evaluaci√≥n\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,                  # Usar todos los cores\n",
    "    early_stopping_rounds=20    # Early stopping\n",
    ")\n",
    "\n",
    "# Entrenar con conjunto de validaci√≥n\n",
    "eval_set = [(X_train_vec, y_train), (X_test_vec, y_test)]\n",
    "modelo.fit(\n",
    "    X_train_vec, y_train,\n",
    "    eval_set=eval_set,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Obtener informaci√≥n del entrenamiento\n",
    "resultado_entrenamiento = modelo.evals_result()\n",
    "if resultado_entrenamiento:\n",
    "    # Obtener el mejor score de la validaci√≥n\n",
    "    val_scores = resultado_entrenamiento['validation_1']['logloss']\n",
    "    mejor_iteracion = np.argmin(val_scores)\n",
    "    mejor_score = val_scores[mejor_iteracion]\n",
    "    print(f\"‚úÖ Mejor iteraci√≥n: {mejor_iteracion + 1}\")\n",
    "    print(f\"‚úÖ Mejor score (logloss): {mejor_score:.4f}\")\n",
    "\n",
    "# Validaci√≥n cruzada con modelo sin early stopping\n",
    "print(\"\\nüìà Realizando validaci√≥n cruzada...\")\n",
    "modelo_cv = xgb.XGBClassifier(\n",
    "    n_estimators=100,  # Menos √°rboles para CV r√°pida\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "scores_cv = cross_val_score(modelo_cv, X_train_vec, y_train, cv=5, scoring='f1')\n",
    "print(f\"   - F1-Scores: {[f'{s:.3f}' for s in scores_cv]}\")\n",
    "print(f\"   - Media: {scores_cv.mean():.3f} (+/- {scores_cv.std() * 2:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# 11. EVALUACI√ìN DETALLADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä EVALUACI√ìN EN CONJUNTO DE PRUEBA:\")\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modelo.predict(X_test_vec)\n",
    "y_pred_proba = modelo.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "# M√©tricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nüéØ M√©tricas principales:\")\n",
    "print(f\"   - Accuracy: {accuracy:.3f}\")\n",
    "print(f\"   - F1-Score: {f1:.3f}\")\n",
    "\n",
    "# Reporte completo\n",
    "print(\"\\nüìã Reporte de clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred, \n",
    "                          target_names=['No T√≥xico', 'T√≥xico'],\n",
    "                          digits=3))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No T√≥xico', 'T√≥xico'],\n",
    "            yticklabels=['No T√≥xico', 'T√≥xico'])\n",
    "plt.title('Matriz de Confusi√≥n - XGBoost')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "\n",
    "# Agregar m√©tricas en el t√≠tulo\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "plt.text(0.5, -0.1, f'Precisi√≥n: {precision:.3f} | Recall: {recall:.3f} | F1: {f1:.3f}', \n",
    "         ha='center', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "# 12. AN√ÅLISIS DE IMPORTANCIA DE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüî§ AN√ÅLISIS DE IMPORTANCIA DE FEATURES:\")\n",
    "\n",
    "# Obtener importancia de features de XGBoost\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "importancias = modelo.feature_importances_\n",
    "\n",
    "# Crear DataFrame de importancias\n",
    "df_importancia = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importancias\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Top 20 features m√°s importantes\n",
    "print(\"\\nüèÜ Top 20 features m√°s importantes:\")\n",
    "for idx, row in df_importancia.head(20).iterrows():\n",
    "    print(f\"   '{row['feature']}': {row['importance']:.4f}\")\n",
    "\n",
    "# Visualizar importancia de features\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = df_importancia.head(30)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Top 30 Features M√°s Importantes - XGBoost')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis adicional: Gain vs Cover\n",
    "if hasattr(modelo, 'get_booster'):\n",
    "    print(\"\\nüìä An√°lisis detallado de importancia:\")\n",
    "    importance_types = ['weight', 'gain', 'cover']\n",
    "    \n",
    "    for imp_type in importance_types:\n",
    "        importances_dict = modelo.get_booster().get_score(importance_type=imp_type)\n",
    "        if importances_dict:\n",
    "            print(f\"\\n{imp_type.upper()}:\")\n",
    "            sorted_imp = sorted(importances_dict.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "            for feat, score in sorted_imp:\n",
    "                if feat.startswith('f'):\n",
    "                    feat_idx = int(feat[1:])\n",
    "                    feat_name = feature_names[feat_idx]\n",
    "                    print(f\"   '{feat_name}': {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# 13. FUNCI√ìN DE PREDICCI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_toxicidad(texto, modelo=modelo, vectorizer=vectorizer):\n",
    "    \"\"\"\n",
    "    Predice si un comentario es t√≥xico.\n",
    "    \n",
    "    Retorna:\n",
    "    - etiqueta: 'T√ìXICO' o 'NO T√ìXICO'\n",
    "    - confianza: probabilidad de la predicci√≥n\n",
    "    \"\"\"\n",
    "    # Preprocesar\n",
    "    texto_limpio = limpiar_texto(texto)\n",
    "    texto_procesado = procesar_texto(texto_limpio)\n",
    "    \n",
    "    # Vectorizar\n",
    "    texto_vec = vectorizer.transform([texto_procesado])\n",
    "    \n",
    "    # Predecir\n",
    "    prediccion = modelo.predict(texto_vec)[0]\n",
    "    probabilidad = modelo.predict_proba(texto_vec)[0, 1]\n",
    "    \n",
    "    etiqueta = \"T√ìXICO ‚ö†Ô∏è\" if prediccion == 1 else \"NO T√ìXICO ‚úÖ\"\n",
    "    confianza = probabilidad if prediccion == 1 else (1 - probabilidad)\n",
    "    \n",
    "    return etiqueta, confianza\n",
    "\n",
    "# Probar con ejemplos\n",
    "print(\"\\nüß™ PRUEBAS CON COMENTARIOS NUEVOS:\")\n",
    "\n",
    "ejemplos = [\n",
    "    \"Great video, thanks for sharing!\",\n",
    "    \"You're so stupid and ignorant\",\n",
    "    \"I disagree with your opinion\",\n",
    "    \"This is garbage content, delete it\",\n",
    "    \"Interesting perspective, never thought about it that way\"\n",
    "]\n",
    "\n",
    "for comentario in ejemplos:\n",
    "    etiqueta, confianza = predecir_toxicidad(comentario)\n",
    "    print(f\"\\nüìù '{comentario}'\")\n",
    "    print(f\"   ‚Üí {etiqueta} (Confianza: {confianza:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# 14. GUARDAR MODELO Y COMPONENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüíæ GUARDANDO MODELO Y COMPONENTES...\")\n",
    "\n",
    "# Nombres de archivo\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "archivo_modelo = f'modelo_toxicidad_xgboost_{timestamp}.pkl'\n",
    "archivo_vectorizer = f'vectorizer_toxicidad_{timestamp}.pkl'\n",
    "\n",
    "# Guardar versiones\n",
    "with open('modelo_toxicidad_xgboost_final.pkl', 'wb') as f:\n",
    "    pickle.dump(modelo, f)\n",
    "\n",
    "with open('vectorizer_toxicidad_final.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(f\"‚úÖ Modelo XGBoost guardado como: {archivo_modelo}\")\n",
    "print(f\"‚úÖ Vectorizador guardado como: {archivo_vectorizer}\")\n",
    "print(f\"‚úÖ Tambi√©n guardados como: modelo_toxicidad_xgboost_final.pkl y vectorizer_toxicidad_final.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# AN√ÅLISIS DE OVERFITTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_overfitting(modelo_xgb, X_train_vec, y_train, X_test_vec, y_test):\n",
    "    \"\"\"\n",
    "    An√°lisis completo de overfitting del modelo XGBoost\n",
    "    Adaptado para el notebook de detecci√≥n de toxicidad\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç AN√ÅLISIS DE OVERFITTING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. M√âTRICAS COMPARATIVAS ENTRE CONJUNTOS\n",
    "    print(\"\\nüìä COMPARACI√ìN DE M√âTRICAS POR CONJUNTO:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    conjuntos_datos = {\n",
    "        'Entrenamiento': (X_train_vec, y_train),\n",
    "        'Prueba': (X_test_vec, y_test)\n",
    "    }\n",
    "    \n",
    "    comparacion_metricas = {}\n",
    "    \n",
    "    for nombre, (X, y) in conjuntos_datos.items():\n",
    "        y_pred = modelo_xgb.predict(X)\n",
    "        y_proba = modelo_xgb.predict_proba(X)[:, 1]\n",
    "        \n",
    "        metricas = {\n",
    "            'accuracy': accuracy_score(y, y_pred),\n",
    "            'precision': precision_score(y, y_pred),\n",
    "            'recall': recall_score(y, y_pred),\n",
    "            'f1': f1_score(y, y_pred),\n",
    "            'auc': roc_auc_score(y, y_proba)\n",
    "        }\n",
    "        \n",
    "        comparacion_metricas[nombre] = metricas\n",
    "        \n",
    "        print(f\"\\n{nombre}:\")\n",
    "        for metrica, valor in metricas.items():\n",
    "            print(f\"  {metrica.upper()}: {valor:.4f}\")\n",
    "    \n",
    "    # 2. DETECTAR OVERFITTING\n",
    "    print(f\"\\nüö® DETECCI√ìN DE OVERFITTING:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    train_f1 = comparacion_metricas['Entrenamiento']['f1']\n",
    "    test_f1 = comparacion_metricas['Prueba']['f1']\n",
    "    \n",
    "    # Diferencias\n",
    "    train_test_diff = train_f1 - test_f1\n",
    "    \n",
    "    print(f\"üìà F1 Train vs Test: {train_test_diff:.4f}\")\n",
    "    \n",
    "    # An√°lisis de overfitting\n",
    "    overfitting_detectado = False\n",
    "    \n",
    "    if train_test_diff > 0.08:  # M√°s de 8% de diferencia es preocupante\n",
    "        print(\"‚ùå OVERFITTING SEVERO detectado (Train >> Test)\")\n",
    "        overfitting_detectado = True\n",
    "    elif train_test_diff > 0.05:  # M√°s de 5% de diferencia\n",
    "        print(\"‚ö†Ô∏è  OVERFITTING MODERADO detectado (Train >> Test)\")\n",
    "        overfitting_detectado = True\n",
    "    elif train_test_diff > 0.02:  # Ligero overfitting\n",
    "        print(\"‚ö†Ô∏è  LIGERO OVERFITTING detectado\")\n",
    "        overfitting_detectado = True\n",
    "    \n",
    "    if not overfitting_detectado:\n",
    "        print(\"‚úÖ NO se detecta overfitting significativo\")\n",
    "        print(\"‚úÖ Modelo tiene buena generalizaci√≥n\")\n",
    "    \n",
    "    return comparacion_metricas\n",
    "\n",
    "def graficar_analisis_overfitting(modelo_xgb, X_train_vec, y_train, X_test_vec, y_test, comparacion_metricas):\n",
    "    \"\"\"\n",
    "    Visualizaciones para an√°lisis de overfitting\n",
    "    Adaptado para el modelo XGBoost del notebook\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüìä GENERANDO VISUALIZACIONES...\")\n",
    "    \n",
    "    # Crear subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('An√°lisis de Overfitting - Modelo XGBoost Toxicidad', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Subplot 1: Curvas de aprendizaje\n",
    "    print(\"üìà Calculando curvas de aprendizaje...\")\n",
    "    \n",
    "    # Crear un modelo XGBoost sin early stopping para las curvas de aprendizaje\n",
    "    modelo_sin_early_stopping = xgb.XGBClassifier(\n",
    "        n_estimators=100,  # Menos √°rboles para ser m√°s r√°pido\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "        # NO incluir early_stopping_rounds aqu√≠\n",
    "    )\n",
    "    \n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        modelo_sin_early_stopping, X_train_vec, y_train,\n",
    "        cv=3, \n",
    "        train_sizes=np.linspace(0.3, 1.0, 6),  # Empezar con m√°s datos para evitar problemas\n",
    "        scoring='f1',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Calcular medias y desviaciones\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    axes[0, 0].plot(train_sizes, train_mean, 'o-', color='blue', label='Entrenamiento', linewidth=2)\n",
    "    axes[0, 0].fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='blue')\n",
    "    \n",
    "    axes[0, 0].plot(train_sizes, val_mean, 'o-', color='red', label='Validaci√≥n Cruzada', linewidth=2)\n",
    "    axes[0, 0].fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2, color='red')\n",
    "    \n",
    "    axes[0, 0].set_xlabel('Tama√±o del conjunto de entrenamiento')\n",
    "    axes[0, 0].set_ylabel('F1 Score')\n",
    "    axes[0, 0].set_title('Curvas de Aprendizaje', fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 2: Comparaci√≥n de m√©tricas Train vs Test\n",
    "    conjuntos = ['Entrenamiento', 'Prueba']\n",
    "    f1_scores = [\n",
    "        comparacion_metricas['Entrenamiento']['f1'],\n",
    "        comparacion_metricas['Prueba']['f1']\n",
    "    ]\n",
    "    \n",
    "    colores = ['lightblue', 'lightcoral']\n",
    "    barras = axes[0, 1].bar(conjuntos, f1_scores, color=colores)\n",
    "    axes[0, 1].set_ylabel('F1 Score')\n",
    "    axes[0, 1].set_title('F1 Score: Entrenamiento vs Prueba', fontweight='bold')\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # A√±adir valores en las barras\n",
    "    for barra, score in zip(barras, f1_scores):\n",
    "        axes[0, 1].text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.01,\n",
    "                       f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # L√≠nea de referencia para mostrar la diferencia\n",
    "    diferencia = abs(f1_scores[0] - f1_scores[1])\n",
    "    axes[0, 1].text(0.5, 0.5, f'Diferencia: {diferencia:.3f}', \n",
    "                   transform=axes[0, 1].transAxes, ha='center',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "    \n",
    "    # Subplot 3: Distribuci√≥n de probabilidades por conjunto\n",
    "    y_proba_train = modelo_xgb.predict_proba(X_train_vec)[:, 1]\n",
    "    y_proba_test = modelo_xgb.predict_proba(X_test_vec)[:, 1]\n",
    "    \n",
    "    axes[1, 0].hist(y_proba_train, bins=30, alpha=0.7, label='Entrenamiento', color='blue', density=True)\n",
    "    axes[1, 0].hist(y_proba_test, bins=30, alpha=0.7, label='Prueba', color='red', density=True)\n",
    "    axes[1, 0].set_xlabel('Probabilidad de Toxicidad')\n",
    "    axes[1, 0].set_ylabel('Densidad')\n",
    "    axes[1, 0].set_title('Distribuci√≥n de Probabilidades Predichas', fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 4: Todas las m√©tricas comparadas\n",
    "    metricas = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']\n",
    "    train_metricas = [comparacion_metricas['Entrenamiento'][m.lower()] for m in metricas]\n",
    "    test_metricas = [comparacion_metricas['Prueba'][m.lower()] for m in metricas]\n",
    "    \n",
    "    x = np.arange(len(metricas))\n",
    "    ancho = 0.35\n",
    "    \n",
    "    axes[1, 1].bar(x - ancho/2, train_metricas, ancho, label='Entrenamiento', color='lightblue')\n",
    "    axes[1, 1].bar(x + ancho/2, test_metricas, ancho, label='Prueba', color='lightcoral')\n",
    "    \n",
    "    axes[1, 1].set_xlabel('M√©tricas')\n",
    "    axes[1, 1].set_ylabel('Score')\n",
    "    axes[1, 1].set_title('Comparaci√≥n Completa de M√©tricas', fontweight='bold')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels(metricas, rotation=45)\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def generar_reporte_overfitting(comparacion_metricas):\n",
    "    \"\"\"\n",
    "    Generar reporte final de overfitting\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüìã REPORTE FINAL DE OVERFITTING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    train_f1 = comparacion_metricas['Entrenamiento']['f1']\n",
    "    test_f1 = comparacion_metricas['Prueba']['f1']\n",
    "    \n",
    "    # An√°lisis detallado\n",
    "    print(f\"üìä AN√ÅLISIS DETALLADO:\")\n",
    "    print(f\"   ‚Ä¢ F1 Entrenamiento: {train_f1:.4f}\")\n",
    "    print(f\"   ‚Ä¢ F1 Prueba:        {test_f1:.4f}\")\n",
    "    \n",
    "    gap_train_test = train_f1 - test_f1\n",
    "    \n",
    "    print(f\"\\nüîç GAP DE RENDIMIENTO:\")\n",
    "    print(f\"   ‚Ä¢ Train-Test gap:   {gap_train_test:.4f}\")\n",
    "    \n",
    "    # Diagn√≥stico\n",
    "    print(f\"\\nü©∫ DIAGN√ìSTICO:\")\n",
    "    \n",
    "    if gap_train_test < 0.02:\n",
    "        print(\"   ‚úÖ EXCELENTE: Modelo muy bien generalizado\")\n",
    "        recomendacion = \"El modelo est√° listo para producci√≥n\"\n",
    "        color_estado = \"üü¢\"\n",
    "        \n",
    "    elif gap_train_test < 0.05:\n",
    "        print(\"   ‚úÖ BUENO: Ligero overfitting, pero aceptable\")\n",
    "        recomendacion = \"Modelo aceptable para producci√≥n con monitoreo\"\n",
    "        color_estado = \"üü°\"\n",
    "        \n",
    "    elif gap_train_test < 0.08:\n",
    "        print(\"   ‚ö†Ô∏è  MODERADO: Overfitting detectado\")\n",
    "        recomendacion = \"Considerar m√°s regularizaci√≥n o early stopping m√°s agresivo\"\n",
    "        color_estado = \"üü†\"\n",
    "        \n",
    "    else:\n",
    "        print(\"   ‚ùå SEVERO: Overfitting significativo\")\n",
    "        recomendacion = \"Necesario ajustar hiperpar√°metros o reentrenar\"\n",
    "        color_estado = \"üî¥\"\n",
    "    \n",
    "    print(f\"\\nüí° RECOMENDACI√ìN:\")\n",
    "    print(f\"   {recomendacion}\")\n",
    "    \n",
    "    # M√©tricas de generalizaci√≥n (no \"confianza\" para evitar confusi√≥n)\n",
    "    puntaje_generalizacion = max(0, 100 - (gap_train_test * 100 * 15))\n",
    "    print(f\"\\nüéØ CAPACIDAD DE GENERALIZACI√ìN: {puntaje_generalizacion:.1f}/100 {color_estado}\")\n",
    "    \n",
    "    if puntaje_generalizacion >= 85:\n",
    "        print(\"   üèÜ EXCELENTE generalizaci√≥n - Modelo muy robusto\")\n",
    "    elif puntaje_generalizacion >= 70:\n",
    "        print(\"   üëç BUENA generalizaci√≥n - Modelo confiable\")\n",
    "    elif puntaje_generalizacion >= 50:\n",
    "        print(\"   ‚ö†Ô∏è  GENERALIZACI√ìN MEDIA - Modelo aceptable con reservas\")\n",
    "    else:\n",
    "        print(\"   üëé GENERALIZACI√ìN BAJA - Hay overfitting, revisar modelo\")\n",
    "    \n",
    "    # An√°lisis adicional espec√≠fico para detecci√≥n de toxicidad\n",
    "    print(f\"\\nüéØ AN√ÅLISIS ESPEC√çFICO PARA TOXICIDAD:\")\n",
    "    \n",
    "    train_precision = comparacion_metricas['Entrenamiento']['precision']\n",
    "    test_precision = comparacion_metricas['Prueba']['precision']\n",
    "    precision_gap = train_precision - test_precision\n",
    "    \n",
    "    train_recall = comparacion_metricas['Entrenamiento']['recall']\n",
    "    test_recall = comparacion_metricas['Prueba']['recall']\n",
    "    recall_gap = train_recall - test_recall\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Gap Precision: {precision_gap:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Gap Recall:    {recall_gap:.4f}\")\n",
    "    \n",
    "    if precision_gap > 0.1:\n",
    "        print(\"   ‚ö†Ô∏è  Modelo podr√≠a estar generando muchos falsos positivos en producci√≥n\")\n",
    "    if recall_gap > 0.1:\n",
    "        print(\"   ‚ö†Ô∏è  Modelo podr√≠a estar perdiendo comentarios t√≥xicos en producci√≥n\")\n",
    "\n",
    "# EJECUTAR AN√ÅLISIS COMPLETO DE OVERFITTING\n",
    "# 1. Analizar overfitting con las m√©tricas\n",
    "comparacion_metricas = analizar_overfitting(\n",
    "    modelo, X_train_vec, y_train, X_test_vec, y_test\n",
    ")\n",
    "\n",
    "# 2. Generar visualizaciones\n",
    "graficar_analisis_overfitting(\n",
    "    modelo, X_train_vec, y_train, X_test_vec, y_test, comparacion_metricas\n",
    ")\n",
    "\n",
    "# 3. Generar reporte final\n",
    "generar_reporte_overfitting(comparacion_metricas)\n",
    "\n",
    "print(f\"\\n‚úÖ AN√ÅLISIS DE OVERFITTING COMPLETADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# AN√ÅLISIS ADICIONAL: PREDICCIONES POR CONFIANZA\n",
    "print(f\"\\nüìà AN√ÅLISIS ADICIONAL: DISTRIBUCI√ìN DE CONFIANZA\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analizar las predicciones por nivel de confianza\n",
    "y_proba_test = modelo.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "# Categorizar predicciones por confianza\n",
    "alta_confianza = (y_proba_test >= 0.8) | (y_proba_test <= 0.2)\n",
    "media_confianza = ((y_proba_test >= 0.6) & (y_proba_test < 0.8)) | ((y_proba_test > 0.2) & (y_proba_test <= 0.4))\n",
    "baja_confianza = (y_proba_test > 0.4) & (y_proba_test < 0.6)\n",
    "\n",
    "print(f\"üìä Distribuci√≥n de confianza en predicciones de prueba:\")\n",
    "print(f\"   ‚Ä¢ Alta confianza (>80% o <20%):  {alta_confianza.sum():3d} ({alta_confianza.mean()*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Media confianza (60-80%, 20-40%): {media_confianza.sum():3d} ({media_confianza.mean()*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Baja confianza (40-60%):       {baja_confianza.sum():3d} ({baja_confianza.mean()*100:.1f}%)\")\n",
    "\n",
    "# Calcular accuracy por nivel de confianza\n",
    "if alta_confianza.sum() > 0:\n",
    "    acc_alta = accuracy_score(y_test[alta_confianza], (y_proba_test[alta_confianza] > 0.5))\n",
    "    print(f\"\\nüéØ Accuracy por nivel de confianza:\")\n",
    "    print(f\"   ‚Ä¢ Alta confianza: {acc_alta:.3f}\")\n",
    "\n",
    "if media_confianza.sum() > 0:\n",
    "    acc_media = accuracy_score(y_test[media_confianza], (y_proba_test[media_confianza] > 0.5))\n",
    "    print(f\"   ‚Ä¢ Media confianza: {acc_media:.3f}\")\n",
    "\n",
    "if baja_confianza.sum() > 0:\n",
    "    acc_baja = accuracy_score(y_test[baja_confianza], (y_proba_test[baja_confianza] > 0.5))\n",
    "    print(f\"   ‚Ä¢ Baja confianza: {acc_baja:.3f}\")\n",
    "\n",
    "print(f\"\\nüí° Interpretaci√≥n:\")\n",
    "if baja_confianza.mean() < 0.15:  # Menos del 15% de predicciones inciertas\n",
    "    print(\"   ‚úÖ Modelo hace predicciones con alta certeza individual\")\n",
    "    print(\"   üìä La mayor√≠a de predicciones son muy seguras (>80% o <20%)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Considerable n√∫mero de predicciones con baja certeza\")\n",
    "    print(\"   üìä Muchas predicciones est√°n en zona gris (40-60%)\")\n",
    "\n",
    "print(f\"\\nüèÅ AN√ÅLISIS COMPLETO FINALIZADO\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# 15. RESUMEN FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ RESUMEN DEL PROYECTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä Dataset:\n",
    "   - Comentarios originales: 1,000\n",
    "   - Despu√©s de augmentation: {len(df_final)}\n",
    "   - Balance final: {df_final['toxic_binary'].mean()*100:.1f}% t√≥xicos\n",
    "\n",
    "üßπ Preprocesamiento:\n",
    "   - Columnas eliminadas: {len(columnas_eliminar)} (desbalanceadas)\n",
    "   - Columnas usadas: {len(columnas_mantener)}\n",
    "   - T√©cnica: Limpieza + Lemmatizaci√≥n\n",
    "\n",
    "üîÑ Data Augmentation:\n",
    "   - M√©todo: Variaciones de texto\n",
    "   - Comentarios t√≥xicos aumentados: {len(df_aumentados)}\n",
    "\n",
    "ü§ñ Modelo:\n",
    "   - Algoritmo: XGBoost\n",
    "   - Par√°metros: 300 √°rboles, profundidad 6, early stopping\n",
    "   - Vectorizaci√≥n: TF-IDF (2000 features, n-gramas 1-3)\n",
    "   - Performance: F1-Score = {f1:.3f}\n",
    "\n",
    "‚úÖ Archivos generados:\n",
    "   - dataset_toxicidad_aumentado.csv\n",
    "   - modelo_toxicidad_xgboost_final.pkl\n",
    "   - vectorizer_toxicidad_final.pkl\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
