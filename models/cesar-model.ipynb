{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"../data/youtoxic_english_1000.csv\")\n",
    "\n",
    "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Revisar columnas con solo ceros o sin representaci√≥n significativa\n",
    "etiquetas = [\n",
    "    \"IsToxic\", \"IsAbusive\", \"IsThreat\", \"IsProvocative\", \"IsObscene\",\n",
    "    \"IsHatespeech\", \"IsRacist\", \"IsNationalist\", \"IsSexist\", \"IsHomophobic\",\n",
    "    \"IsReligiousHate\", \"IsRadicalism\"\n",
    "]\n",
    "\n",
    "# Mostrar cu√°ntas veces aparece \"True\" en cada etiqueta\n",
    "print(\"Etiquetas activas:\")\n",
    "print(df[etiquetas].sum().sort_values())\n",
    "\n",
    "# 2. Eliminar columnas sin representaci√≥n (sum == 0 o sum == 1)\n",
    "etiquetas_utiles = [col for col in etiquetas if df[col].sum() > 1]\n",
    "print(\"\\nEtiquetas que conservaremos:\", etiquetas_utiles)\n",
    "\n",
    "# 3. Eliminar columnas irrelevantes para el modelado\n",
    "columnas_irrelevantes = [\"CommentId\", \"VideoId\"]\n",
    "df.drop(columns=columnas_irrelevantes, inplace=True)\n",
    "\n",
    "# 4. (Opcional) Eliminar duplicados por texto\n",
    "df.drop_duplicates(subset=\"Text\", inplace=True)\n",
    "\n",
    "# 5. Dejar el DataFrame con solo las columnas √∫tiles\n",
    "columnas_utiles = [\"Text\"] + etiquetas_utiles\n",
    "df = df[columnas_utiles]\n",
    "\n",
    "# 6. Confirmar\n",
    "print(f\"\\nDataset limpio ‚Üí Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Limpieza previa del dataset\n",
    "\n",
    "Antes de aplicar el preprocesamiento textual, revisamos las columnas del dataset:\n",
    "\n",
    "- Eliminamos etiquetas que **no tienen representaci√≥n suficiente** (por ejemplo, `IsHomophobic`, `IsRadicalism`) ya que no aportar√≠an valor al modelo.\n",
    "- Quitamos columnas irrelevantes como `CommentId` y `VideoId`.\n",
    "- Eliminamos posibles duplicados exactos en los comentarios (`Text`).\n",
    "\n",
    "Esto nos permite trabajar sobre un dataset m√°s limpio, centrado en los comentarios y en las etiquetas que tienen informaci√≥n √∫til. De este modo, evitamos introducir ruido o clases vac√≠as en el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Cargar modelo de ingl√©s\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Funci√≥n para limpiar y lematizar texto\n",
    "def preprocesar_texto(texto):\n",
    "    # 1. Eliminar URLs, s√≠mbolos especiales y n√∫meros\n",
    "    texto = re.sub(r\"http\\S+|www\\S+|[^a-zA-Z\\s]\", \"\", texto.lower())\n",
    "    \n",
    "    # 2. Procesar con SpaCy\n",
    "    doc = nlp(texto)\n",
    "\n",
    "    # 3. Eliminar stopwords y obtener lemas\n",
    "    tokens_limpios = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    return \" \".join(tokens_limpios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limpieza sobre una copia del texto\n",
    "df[\"CleanText\"] = df[\"Text\"].apply(preprocesar_texto)\n",
    "\n",
    "# Ver resultado en 3 ejemplos\n",
    "df[[\"Text\", \"CleanText\"]].sample(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Preprocesamiento del texto con SpaCy\n",
    "\n",
    "En este paso limpiamos y normalizamos los comentarios para que puedan ser procesados por modelos de machine learning. Para ello utilizamos **SpaCy**, una librer√≠a especializada en procesamiento de lenguaje natural.\n",
    "\n",
    "Nuestra funci√≥n `preprocesar_texto()` realiza las siguientes tareas:\n",
    "\n",
    "1. **Elimina elementos innecesarios** del texto original:\n",
    "   - URLs, s√≠mbolos, n√∫meros y puntuaci√≥n.\n",
    "   - Convierte todo a min√∫sculas.\n",
    "\n",
    "2. **Tokeniza** (divide en palabras) y procesa cada palabra con SpaCy:\n",
    "   - Elimina las **palabras vac√≠as** (*stopwords*) como \"the\", \"you\", \"and\".\n",
    "   - Obtiene la **forma base** (*lema*) de cada palabra, por ejemplo:\n",
    "     - \"running\" ‚Üí \"run\"\n",
    "     - \"was\" ‚Üí \"be\"\n",
    "     - \"better\" ‚Üí \"good\"\n",
    "\n",
    "3. **Reconstruye el texto limpio**, que usaremos como entrada para vectorizaci√≥n y modelado.\n",
    "\n",
    "Este preprocesamiento mejora significativamente la calidad de las caracter√≠sticas que extraeremos del texto, ya que reduce el ruido y normaliza el lenguaje.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto puede tardar unos segundos la primera vez (1.000 textos)\n",
    "df[\"CleanText\"] = df[\"Text\"].apply(preprocesar_texto)\n",
    "\n",
    "# Comprobar algunos ejemplos de texto original vs limpio\n",
    "df[[\"Text\", \"CleanText\"]].sample(5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Crear los vectorizadores\n",
    "vectorizer_bow = CountVectorizer(max_features=20)\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=20)\n",
    "\n",
    "# Aplicar sobre el texto limpio\n",
    "X_bow = vectorizer_bow.fit_transform(df[\"CleanText\"])\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(df[\"CleanText\"])\n",
    "\n",
    "# Convertir a DataFrames para verlos\n",
    "df_bow = pd.DataFrame(X_bow.toarray(), columns=vectorizer_bow.get_feature_names_out())\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=vectorizer_tfidf.get_feature_names_out())\n",
    "\n",
    "# Mostrar las primeras filas de cada uno\n",
    "print(\"Bag of Words:\")\n",
    "display(df_bow.head())\n",
    "\n",
    "print(\"TF-IDF:\")\n",
    "display(df_tfidf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Comparaci√≥n entre Bag of Words y TF-IDF\n",
    "\n",
    "Ambas t√©cnicas convierten texto en vectores num√©ricos, pero lo hacen de forma distinta:\n",
    "\n",
    "- **Bag of Words** simplemente cuenta cu√°ntas veces aparece cada palabra.\n",
    "- **TF-IDF** ajusta esos conteos seg√∫n la rareza de cada palabra en el conjunto total.\n",
    "\n",
    "#### ¬øQu√© vemos?\n",
    "- En BoW, los valores son enteros (frecuencias puras).\n",
    "- En TF-IDF, los valores son decimales ‚Üí ajustados por importancia.\n",
    "- Palabras comunes (como \"people\") tendr√°n menos peso en TF-IDF si aparecen en casi todos los comentarios.\n",
    "\n",
    "Ambas representaciones son √∫tiles, pero **TF-IDF suele funcionar mejor en clasificaci√≥n** al eliminar ruido estad√≠stico y destacar las palabras que verdaderamente diferencian un texto de otro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî§ Vocabulario BoW:\")\n",
    "print(vectorizer_bow.get_feature_names_out())\n",
    "\n",
    "print(\"\\nüî§ Vocabulario TF-IDF:\")\n",
    "print(vectorizer_tfidf.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparsity de BoW\n",
    "sparsity_bow = 1.0 - (X_bow.count_nonzero() / float(X_bow.shape[0] * X_bow.shape[1]))\n",
    "print(f\"Sparsity BoW: {sparsity_bow:.2%}\")\n",
    "\n",
    "# Sparsity de TF-IDF\n",
    "sparsity_tfidf = 1.0 - (X_tfidf.count_nonzero() / float(X_tfidf.shape[0] * X_tfidf.shape[1]))\n",
    "print(f\"Sparsity TF-IDF: {sparsity_tfidf:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Comparaci√≥n de vocabulario y sparsity entre BoW y TF-IDF\n",
    "\n",
    "Despu√©s de aplicar las t√©cnicas de vectorizaci√≥n, hemos comparado:\n",
    "\n",
    "#### El vocabulario generado\n",
    "Ambos m√©todos (`CountVectorizer` y `TfidfVectorizer`) seleccionaron las 20 palabras m√°s frecuentes en el dataset. Estas palabras forman el **vocabulario base** sobre el cual se construyen los vectores num√©ricos de cada comentario.\n",
    "\n",
    "Aunque el vocabulario es el mismo en este caso (por usar `max_features=20`), las **frecuencias que asignan a cada palabra son diferentes**:\n",
    "\n",
    "#### Sparsity (dispersi√≥n de la matriz)\n",
    "Calculamos la **sparsity** de ambas matrices, es decir, el porcentaje de celdas con valor cero. El resultado fue:\n",
    "\n",
    "- Sparsity BoW: **90.52%**\n",
    "- Sparsity TF-IDF: **90.52%**\n",
    "\n",
    "Esto significa que m√°s del 90% de los valores en ambas matrices son ceros, lo cual es normal en NLP cuando la mayor√≠a de las palabras **no aparecen en la mayor√≠a de los textos**. Aun as√≠, este tipo de representaci√≥n dispersa funciona bien en modelos de clasificaci√≥n textual, especialmente con TF-IDF que reduce el ruido de palabras demasiado comunes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Dividir datos en entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, df[\"IsToxic\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Entrenar modelo base\n",
    "modelo_lr = LogisticRegression(max_iter=1000)\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predecir sobre el conjunto de test\n",
    "y_pred = modelo_lr.predict(X_test)\n",
    "\n",
    "# 4. M√©tricas\n",
    "print(\"üìä Reporte de clasificaci√≥n:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "# 5. Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No T√≥xico\", \"T√≥xico\"], yticklabels=[\"No T√≥xico\", \"T√≥xico\"])\n",
    "plt.xlabel(\"Predicci√≥n\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"üîç Matriz de Confusi√≥n - Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "# 6. Accuracy global\n",
    "print(f\"‚úîÔ∏è Accuracy del modelo: {accuracy_score(y_test, y_pred):.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Primer modelo de clasificaci√≥n con TF-IDF + Logistic Regression\n",
    "\n",
    "En esta celda hemos entrenado nuestro primer modelo de machine learning para detectar comentarios t√≥xicos utilizando el texto preprocesado y vectorizado con **TF-IDF**.\n",
    "\n",
    "#### ¬øQu√© hicimos?\n",
    "1. **Divisi√≥n de datos**\n",
    "   - Separamos el dataset en un 80% para entrenamiento y 20% para prueba.\n",
    "   - Esto nos permite evaluar el modelo con ejemplos que nunca ha visto.\n",
    "\n",
    "2. **Entrenamiento**\n",
    "   - Usamos un modelo de regresi√≥n log√≠stica (`LogisticRegression`), ideal como punto de partida en clasificaci√≥n binaria.\n",
    "\n",
    "3. **Evaluaci√≥n**\n",
    "   - Calculamos m√©tricas como **precisi√≥n, recall y F1-score** para ambas clases (`t√≥xico` y `no t√≥xico`).\n",
    "   - Generamos una **matriz de confusi√≥n** para visualizar los aciertos y errores del modelo.\n",
    "   - Mostramos el **accuracy general** del modelo.\n",
    "\n",
    "#### ¬øQu√© esperamos aqu√≠?\n",
    "Este modelo es nuestra l√≠nea base (*baseline*). No se ha optimizado a√∫n, pero ya nos permite:\n",
    "- Ver si el texto limpio y vectorizado con TF-IDF ofrece buena se√±al.\n",
    "- Identificar si el modelo tiene sesgos (por ejemplo, si falla mucho en detectar comentarios t√≥xicos).\n",
    "- Comparar en el futuro con modelos m√°s complejos.\n",
    "\n",
    "Este paso marca el comienzo de la fase de modelado y nos da una primera medida de rendimiento que intentaremos superar con t√©cnicas m√°s avanzadas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
