{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Aumento de datos (Text Augmentation)\n",
    "\n",
    "### Objetivo\n",
    "En este notebook vamos a aplicar t√©cnicas de data augmentation sobre los comentarios t√≥xicos\n",
    "del dataset original, con el objetivo de aumentar el n√∫mero de ejemplos de la clase 1 (IsToxic)\n",
    "y mejorar la capacidad de generalizaci√≥n del modelo.\n",
    "\n",
    "En esta primera fase, usamos la t√©cnica de reemplazo de sin√≥nimos con WordNet a trav√©s\n",
    "de la librer√≠a NLPaug. Esto genera versiones modificadas de los textos t√≥xicos manteniendo\n",
    "su significado general, permitiendo al modelo aprender con m√°s ejemplos variados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Descargar recursos de WordNet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Cargar dataset original\n",
    "df = pd.read_csv(\"../data/youtoxic_english_1000.csv\")\n",
    "df_toxic = df[df[\"IsToxic\"] == 1].copy()\n",
    "\n",
    "# üîÅ Augmentation con sin√≥nimos (WordNet)\n",
    "syn_aug = naw.SynonymAug(aug_src='wordnet')\n",
    "df_toxic[\"augmented\"] = df_toxic[\"Text\"].apply(lambda x: syn_aug.augment(x))\n",
    "\n",
    "# üëÄ Visualizar ejemplos\n",
    "def mostrar_ejemplos(df_tox, n=5):\n",
    "    for i in range(n):\n",
    "        print(f\"\\nüîπ ORIGINAL: {df_tox.iloc[i]['Text']}\")\n",
    "        print(f\"üî∏ AUGMENTED: {df_tox.iloc[i]['augmented']}\")\n",
    "\n",
    "mostrar_ejemplos(df_toxic)\n",
    "\n",
    "# Unir datos originales + aumentados\n",
    "df_aug = pd.DataFrame({\n",
    "    \"Text\": df_toxic[\"augmented\"],\n",
    "    \"IsToxic\": 1\n",
    "})\n",
    "\n",
    "df_full = pd.concat([df, df_aug], ignore_index=True)\n",
    "\n",
    "# Verificar balance de clases\n",
    "print(\"\\n‚úÖ Recuento por clase tras augmentaci√≥n:\")\n",
    "print(df_full[\"IsToxic\"].value_counts())\n",
    "\n",
    "# Guardar nuevo dataset para reentrenamiento posterior\n",
    "df_full.to_csv(\"../data/youtoxic_augmented.csv\", index=False)\n",
    "print(\"\\nüíæ Dataset aumentado guardado como 'youtoxic_augmented.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import time\n",
    "\n",
    "# Cargamos el dataset aumentado\n",
    "df_augmented = pd.read_csv(\"../data/youtoxic_augmented.csv\")\n",
    "\n",
    "# Filtramos solo los t√≥xicos\n",
    "df_toxic = df_augmented[df_augmented[\"IsToxic\"] == 1].copy()\n",
    "\n",
    "# Funci√≥n de back translation: Ingl√©s ‚ûù Espa√±ol ‚ûù Ingl√©s\n",
    "def back_translate(text):\n",
    "    try:\n",
    "        spanish = GoogleTranslator(source='en', target='es').translate(text)\n",
    "        english = GoogleTranslator(source='es', target='en').translate(spanish)\n",
    "        time.sleep(0.5)  # para evitar l√≠mite de Google\n",
    "        return english\n",
    "    except Exception as e:\n",
    "        print(f\"Error con el texto: {text[:50]}... ‚ûù {e}\") \n",
    "        return text\n",
    "\n",
    "# Aplicamos la funci√≥n\n",
    "df_toxic[\"back_translated\"] = df_toxic[\"Text\"].apply(back_translate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos DataFrame con los nuevos ejemplos\n",
    "df_back = pd.DataFrame({\n",
    "    \"Text\": df_toxic[\"back_translated\"],\n",
    "    \"IsToxic\": 1\n",
    "})\n",
    "\n",
    "# Unimos al dataset ya aumentado\n",
    "df_final = pd.concat([df_augmented, df_back], ignore_index=True)\n",
    "\n",
    "# Guardamos la nueva versi√≥n ampliada\n",
    "df_final.to_csv(\"../data/youtoxic_augmented_backtranslated.csv\", index=False)\n",
    "print(\"üíæ Dataset final guardado como 'youtoxic_augmented_backtranslated.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
