{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Interpretabilidad del modelo de detecci√≥n de comentarios t√≥xicos\n",
    "\n",
    "Este an√°lisis tiene como objetivo explicar de forma clara y visual c√≥mo el modelo de clasificaci√≥n de comentarios t√≥xicos toma sus decisiones.\n",
    "\n",
    "Utilizaremos la librer√≠a **SHAP** para interpretar los resultados del modelo. SHAP nos ayuda a entender qu√© palabras influyen m√°s en que un comentario sea clasificado como t√≥xico o no.\n",
    "\n",
    "Este an√°lisis est√° pensado para ser comprendido tanto por perfiles t√©cnicos como no t√©cnicos (stakeholders).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos modelo y vectorizador\n",
    "model = joblib.load(\"../final_model/modelo_toxicidad_xgboost_final.pkl\")\n",
    "vectorizer = joblib.load(\"../final_model/vectorizer_toxicidad_final.pkl\")\n",
    "\n",
    "# Comentarios de ejemplo\n",
    "comments = [\n",
    "    \"You're disgusting and stupid.\",          # t√≥xico\n",
    "    \"Thank you for this amazing explanation.\", # no t√≥xico\n",
    "    \"I don't think this was helpful at all.\"   # ambiguo\n",
    "]\n",
    "\n",
    "# Vectorizamos comentarios\n",
    "X = vectorizer.transform(comments)\n",
    "\n",
    "# Obtenemos los nombres reales de las features (tokens del vocabulario)\n",
    "feature_names = vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el explicador SHAP con nombres reales\n",
    "explainer = shap.Explainer(model, feature_names=feature_names)\n",
    "\n",
    "# Obtenemos valores SHAP para cada comentario vectorizado\n",
    "shap_values = explainer(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los tokens m√°s influyentes a nivel global (positivo y negativo)\n",
    "shap.summary_plot(shap_values, X, feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### üåç An√°lisis global con SHAP: ¬øQu√© palabras influyen m√°s en el modelo?\n",
    "\n",
    "Este gr√°fico resume qu√© tokens (palabras) son m√°s influyentes en las decisiones del modelo a nivel global.\n",
    "\n",
    "- En el eje vertical se muestran las **palabras m√°s relevantes** seg√∫n el modelo.\n",
    "- En el eje horizontal se representa cu√°nto **impacta cada palabra en la predicci√≥n de toxicidad**.\n",
    "- Cada punto corresponde a una predicci√≥n individual. \n",
    "- El color indica cu√°nto pes√≥ esa palabra en ese comentario concreto (rojo = alto peso TF-IDF, azul = bajo).\n",
    "\n",
    "üî¥ Palabras como **\"stupid\"**, **\"fuck\"**, **\"idiot\"**, **\"shit\"** o **\"fucking\"** tienen un impacto fuerte y consistente en que el modelo clasifique un comentario como t√≥xico.\n",
    "\n",
    "Este gr√°fico demuestra que el modelo ha aprendido a identificar correctamente expresiones ofensivas y cargadas emocionalmente, y que **no act√∫a como una caja negra**, sino que basa sus decisiones en tokens comprensibles y l√≥gicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)  # ‚úÖ Ahora muestra los tokens correctamente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Influencia media de los tokens en el modelo\n",
    "\n",
    "Este gr√°fico muestra los tokens que m√°s han influido en el modelo, **en promedio**, a lo largo de todas las predicciones.\n",
    "\n",
    "- El valor representa la **magnitud media** de impacto de cada token, sin importar si el impacto fue positivo (t√≥xico) o negativo (no t√≥xico).\n",
    "- Cuanto m√°s alta es la barra, **m√°s decisivo es ese token** en las decisiones del modelo.\n",
    "\n",
    "üîù En el top aparecen insultos claros como **\"stupid\"**, **\"fuck\"**, **\"idiot\"**, as√≠ como t√©rminos relacionados con contextos violentos o controversiales como **\"shoot\"**, **\"thug\"**, **\"ferguson\"**, o **\"black\"**.\n",
    "\n",
    "Este gr√°fico refuerza que el modelo ha aprendido a identificar **palabras con alta carga emocional o social** como factores clave para detectar comentarios t√≥xicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Reflexi√≥n cr√≠tica: posibles sesgos y asociaciones espurias\n",
    "\n",
    "Uno de los tokens destacados en los gr√°ficos SHAP es **\"ferguson\"**. Aunque no es una palabra ofensiva en s√≠ misma, aparece con una contribuci√≥n media notable en las predicciones de toxicidad.\n",
    "\n",
    "Este caso es un ejemplo de lo que en aprendizaje autom√°tico se conoce como **asociaci√≥n espuria**: el modelo ha aprendido que la palabra \"ferguson\" suele aparecer en comentarios t√≥xicos, no porque sea una palabra t√≥xica, sino por el contexto social o medi√°tico en el que fue utilizada en el dataset original.\n",
    "\n",
    "Esto revela un posible **sesgo en los datos de entrenamiento**. Si no se revisa, el modelo podr√≠a clasificar como t√≥xicos comentarios informativos o respetuosos que simplemente mencionen ciertos temas o lugares sensibles.\n",
    "\n",
    "üîç Este hallazgo justifica el uso de t√©cnicas de interpretabilidad como **SHAP**, que nos permiten no solo entender c√≥mo decide el modelo, sino tambi√©n detectar y corregir errores, sesgos o asociaciones no deseadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Comentario 1: T√≥xico\n",
    "plt.figure()\n",
    "shap.plots.waterfall(shap_values[0], max_display=10, show=False)\n",
    "plt.title(\"Comentario 1 ‚Äì T√≥xico\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comentario 2: No t√≥xico\n",
    "plt.figure()\n",
    "shap.plots.waterfall(shap_values[1], max_display=10, show=False)\n",
    "plt.title(\"Comentario 2 ‚Äì No t√≥xico\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comentario 3: Ambiguo\n",
    "plt.figure()\n",
    "shap.plots.waterfall(shap_values[2], max_display=10, show=False)\n",
    "plt.title(\"Comentario 3 ‚Äì Ambiguo\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Ejemplos concretos: ¬øC√≥mo decide el modelo en cada comentario?\n",
    "\n",
    "Estos gr√°ficos representan la decisi√≥n del modelo para comentarios concretos. Se visualizan con SHAP (`waterfall`) y muestran:\n",
    "\n",
    "- En rojo: palabras que empujan la predicci√≥n hacia **t√≥xico**\n",
    "- En azul: palabras que empujan hacia **no t√≥xico**\n",
    "- `1 = palabra` indica que el token est√° presente en el comentario\n",
    "- `0 = palabra` indica que no aparece, pero su efecto se estima\n",
    "\n",
    "---\n",
    "\n",
    "### üî¥ Ejemplo 1 ‚Äì Comentario clasificado como t√≥xico (f(x) = 0.315)\n",
    "\n",
    "- El √∫nico token presente que tiene un gran impacto es **\"stupid\"**\n",
    "- El modelo asigna una fuerte contribuci√≥n positiva a este insulto, suficiente para decidir que el comentario es t√≥xico\n",
    "- Los dem√°s tokens no est√°n presentes y no afectan\n",
    "\n",
    "---\n",
    "\n",
    "### üîµ Ejemplo 2 ‚Äì Comentario clasificado como no t√≥xico (f(x) = ‚Äì0.664)\n",
    "\n",
    "- Aunque el comentario contiene palabras sensibles, ninguna de ellas estaba realmente activa en este caso\n",
    "- El modelo no considera que el texto sea insultante\n",
    "- Esto demuestra que **el modelo distingue entre contexto tem√°tico y lenguaje ofensivo**\n",
    "\n",
    "---\n",
    "\n",
    "üîé Gracias a esta explicaci√≥n local, confirmamos que el modelo:\n",
    "- No act√∫a como una caja negra\n",
    "- No penaliza por tema o grupo social, sino por el uso real de insultos directos\n",
    "- Puede tener tokens con riesgo de sesgo, pero su activaci√≥n real depende del contenido\n",
    "\n",
    "Estas explicaciones aumentan la confianza en el modelo y permiten identificar posibles errores o injusticias antes de llevarlo a producci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comentario cr√≠tico pero no ofensivo\n",
    "comment_critico = [\"According to CNN, the Ferguson case sparked a national debate on police violence.\"]\n",
    "\n",
    "# Vectorizar y generar SHAP\n",
    "X_test = vectorizer.transform(comment_critico)\n",
    "X_test_named = pd.DataFrame(X_test.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "shap_test = explainer(X_test_named)\n",
    "\n",
    "# Visualizar con t√≠tulo personalizado\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "shap.plots.waterfall(shap_test[0], max_display=10, show=False)\n",
    "plt.title(\"Comentario no ofensivo etiquetado como t√≥xico\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n cr√≠tica: ¬øpuede el modelo equivocarse?\n",
    "\n",
    "A modo de cierre, hemos utilizado SHAP para analizar c√≥mo el modelo reacciona ante un comentario **neutral y objetivo**, que menciona un tema sensible pero sin utilizar lenguaje ofensivo.\n",
    "\n",
    "**Comentario analizado:**\n",
    "_\"According to CNN, the Ferguson case sparked a national debate on police violence.\"_\n",
    "\n",
    "Aunque este comentario es informativo y no insultante, el modelo lo clasifica como **t√≥xico** debido a tokens como `\"ferguson\"` o `\"cnn\"`.\n",
    "\n",
    "Esto evidencia que el modelo ha aprendido **asociaciones espurias**, es decir, palabras que aparecen en contextos t√≥xicos pero **no son t√≥xicas por s√≠ mismas**.\n",
    "\n",
    "---\n",
    "\n",
    "Esta observaci√≥n justifica la importancia de:\n",
    "\n",
    "- Utilizar herramientas de interpretabilidad como SHAP\n",
    "- Evaluar el comportamiento del modelo en casos l√≠mite\n",
    "- Realizar validaciones peri√≥dicas con nuevos ejemplos\n",
    "- Revisar el dataset de entrenamiento y ampliarlo si es necesario\n",
    "\n",
    "üß© La interpretabilidad no solo sirve para entender c√≥mo decide el modelo, sino para **detectar fallos, corregir sesgos y mejorar la equidad del sistema**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comentario cr√≠tico que no es insultante\n",
    "comment = [\"According to CNN, the Ferguson case sparked a national debate on police violence.\"]\n",
    "\n",
    "# Vectorizar\n",
    "X_test = vectorizer.transform(comment)\n",
    "X_test_named = pd.DataFrame(X_test.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Predecir probabilidad\n",
    "f_x = model.predict_proba(X_test)[0][1]\n",
    "print(f\"üîç Probabilidad de toxicidad (f(x)) = {f_x:.3f}\")\n",
    "\n",
    "# Clasificaci√≥n final\n",
    "umbral = 0.5\n",
    "es_toxico = int(f_x >= umbral)\n",
    "print(f\"üè∑Ô∏è Clasificaci√≥n final: {'T√≥xico' if es_toxico else 'No t√≥xico'} (umbral = {umbral})\")\n",
    "\n",
    "# Explicaci√≥n SHAP\n",
    "shap_expl = explainer(X_test_named)\n",
    "shap.plots.waterfall(shap_expl[0], max_display=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n cr√≠tica del modelo.\n",
    "\n",
    "En este an√°lisis utilizamos un comentario que menciona temas sensibles pero sin insultos:\n",
    "\n",
    "_\"According to CNN, the Ferguson case sparked a national debate on police violence.\"_\n",
    "\n",
    "Aunque SHAP detecta tokens que suelen estar presentes en comentarios t√≥xicos (como `\"ferguson\"` o `\"cnn\"`), la **probabilidad final calculada (`f(x)`) es inferior a 0.5**, por lo que el modelo **no lo clasifica como t√≥xico**.\n",
    "\n",
    "---\n",
    "\n",
    "üîç **Conclusi√≥n:**\n",
    "- SHAP muestra **c√≥mo influye cada palabra**, pero no decide por s√≠ solo\n",
    "- El modelo solo clasifica como t√≥xico si la suma de esas influencias supera el umbral (0.5)\n",
    "- Esto demuestra que el modelo **no act√∫a con sesgos autom√°ticos**, sino con equilibrio y contexto\n",
    "- La combinaci√≥n de SHAP + predicci√≥n num√©rica permite detectar **casos l√≠mite, asociaciones espurias y necesidades de revisi√≥n**\n",
    "\n",
    "üí° Este tipo de an√°lisis es fundamental para validar la robustez del modelo antes de usarlo en producci√≥n o en contextos sensibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Conclusiones finales y reflexi√≥n cr√≠tica\n",
    "\n",
    "Durante este an√°lisis, hemos evaluado no solo el rendimiento del modelo de clasificaci√≥n de toxicidad, sino tambi√©n su **capacidad de toma de decisiones y los posibles sesgos presentes** en su razonamiento interno, gracias a la interpretabilidad con SHAP.\n",
    "\n",
    "A trav√©s de gr√°ficos individuales (`waterfall`) y globales (`bar`), hemos podido identificar qu√© tokens tienen m√°s peso en la toma de decisiones del modelo y c√≥mo interact√∫an en diferentes tipos de comentarios (t√≥xicos, neutros y ambiguos).\n",
    "\n",
    "---\n",
    "\n",
    "### ¬øTiene sesgos nuestro modelo?\n",
    "\n",
    "**S√≠, muestra indicios de sesgos contextuales aprendidos durante el entrenamiento**, aunque no siempre se traducen en clasificaciones err√≥neas.\n",
    "\n",
    "#### Justificaci√≥n:\n",
    "\n",
    "- Palabras sensibles como `\"ferguson\"`, `\"cnn\"`, `\"black\"`, `\"african american\"`, `\"muslim\"`, etc. aparecen recurrentemente como tokens que **empujan hacia la predicci√≥n de toxicidad**, tanto en gr√°ficos individuales como globales.\n",
    "\n",
    "- En algunos comentarios **objetivos y no ofensivos**, el modelo muestra una **probabilidad elevada de toxicidad**, lo que indica que asocia ciertas palabras a patrones aprendidos como \"t√≥xicos\", **sin tener en cuenta el tono real del comentario**.\n",
    "\n",
    "- Sin embargo, el modelo **no clasifica autom√°ticamente como t√≥xicos** todos los comentarios que contienen esos t√©rminos. Esto sugiere que:\n",
    "\n",
    "  üîµ El modelo **no tiene un sesgo absoluto ni determinista**  \n",
    "  üî¥ Pero s√≠ ha aprendido **correlaciones espurias**  \n",
    "  _(Ejemplo: \"ferguson\" aparece en muchos comentarios t√≥xicos del dataset ‚Üí el modelo lo aprende como indicador de toxicidad)_\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusi√≥n cr√≠tica y valor a√±adido de SHAP\n",
    "\n",
    "Este an√°lisis muestra que el modelo, aunque funcional, **refleja los sesgos latentes de los datos de entrenamiento**. Por ello:\n",
    "\n",
    "- **SHAP es fundamental no solo para explicar predicciones, sino tambi√©n para auditar el modelo**\n",
    "- Detectar tokens con impacto indebido permite reflexionar sobre la necesidad de:\n",
    "  - Mejorar el dataset (m√°s ejemplos neutrales con palabras sensibles)\n",
    "  - Aplicar t√©cnicas de balanceo o filtrado sem√°ntico\n",
    "  - Incluir controles √©ticos antes de producci√≥n\n",
    "\n",
    "üí° En definitiva, este an√°lisis no solo explica el \"qu√©\" del modelo, sino tambi√©n el \"por qu√©\", y **abre la puerta a una mejora consciente y responsable de la IA aplicada al lenguaje.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
